{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Binary reponse models for panel data\n",
    "\n",
    "### Econometrics B (ØkB)\n",
    "\n",
    "Wooldridge (2010, Section 15.8)\n",
    "\n",
    "Bertel Schjerning\n",
    "\n",
    "Department of Economics, University of Copenhagen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plan for panel data models for binary response\n",
    "1. Binary response models without unobserved effects\n",
    "2. Unobserved effects models under strict exogeneity\n",
    "3. Dynamic unobserved effects models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Panel data\n",
    "\n",
    "$T$ observations of $N$ individuals\n",
    "$$\n",
    "y_{it},x_{it}\\text{,  }i=1,...,N\\text{, }t=1,..,T\n",
    "$$\n",
    "where $y_{it}=\\left \\{ 0,1\\right \\} $ is a binary random variable\n",
    "\n",
    "As usual, we assume random sampling over $i$ (but not over $t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Panel data: Married women's labor force participation\n",
    "- Main empirical example thoughout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>lfp</th>\n",
       "      <th>black</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>agesq</th>\n",
       "      <th>kids</th>\n",
       "      <th>hinc</th>\n",
       "      <th>per1</th>\n",
       "      <th>per2</th>\n",
       "      <th>per3</th>\n",
       "      <th>per4</th>\n",
       "      <th>per5</th>\n",
       "      <th>lhinc</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>1369</td>\n",
       "      <td>2</td>\n",
       "      <td>2308.281006</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.744258</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>1369</td>\n",
       "      <td>2</td>\n",
       "      <td>2529.024414</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.835589</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>1369</td>\n",
       "      <td>2</td>\n",
       "      <td>2462.321289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.808860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>1369</td>\n",
       "      <td>2</td>\n",
       "      <td>2427.562500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.794643</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>1369</td>\n",
       "      <td>2</td>\n",
       "      <td>2409.660156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.787241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>3603.627686</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.189696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>1509.604492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.319603</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>1489.667603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.306308</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>1413.338989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.253710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>1215.146729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.102620</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  period  lfp  black  educ  age  agesq  kids         hinc  per1  per2  \\\n",
       "30   7       1    1      1    12   37   1369     2  2308.281006     1     0   \n",
       "31   7       2    1      1    12   37   1369     2  2529.024414     0     1   \n",
       "32   7       3    1      1    12   37   1369     2  2462.321289     0     0   \n",
       "33   7       4    1      1    12   37   1369     2  2427.562500     0     0   \n",
       "34   7       5    1      1    12   37   1369     2  2409.660156     0     0   \n",
       "35   8       1    1      0    18   29    841     1  3603.627686     1     0   \n",
       "36   8       2    1      0    18   29    841     1  1509.604492     0     1   \n",
       "37   8       3    1      0    18   29    841     1  1489.667603     0     0   \n",
       "38   8       4    1      0    18   29    841     1  1413.338989     0     0   \n",
       "39   8       5    1      0    18   29    841     1  1215.146729     0     0   \n",
       "\n",
       "    per3  per4  per5     lhinc  const  \n",
       "30     0     0     0  7.744258    1.0  \n",
       "31     0     0     0  7.835589    1.0  \n",
       "32     1     0     0  7.808860    1.0  \n",
       "33     0     1     0  7.794643    1.0  \n",
       "34     0     0     1  7.787241    1.0  \n",
       "35     0     0     0  8.189696    1.0  \n",
       "36     0     0     0  7.319603    1.0  \n",
       "37     1     0     0  7.306308    1.0  \n",
       "38     0     1     0  7.253710    1.0  \n",
       "39     0     0     1  7.102620    1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_stata('lfp.dta')\n",
    "Nobs=df['id'].count()\n",
    "df['const']=np.ones((Nobs,1))\n",
    "df[30:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some more Python Libraries and variables used in various specifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as la\n",
    "from tabulate import tabulate\n",
    "import linearpaneldata as lpd   # simple routines to do linear FE and Pooled OLS regressions\n",
    "from indexmodels import *       # objective functions etc. for estimation of panel data binary response models\n",
    "import mestim as M              # routines for M-estimation given general sample objective functions\n",
    "\n",
    "# names of variables use thoughout\n",
    "y_it=['lfp']                           # binary response variable: Labor force participation\n",
    "x_it=['kids', 'lhinc']                 # time varying explanatory varibles  \n",
    "x_t=['per2', 'per3', 'per4', 'per5']   # time dummies (leave one out)\n",
    "x_i=['educ','black', 'age', 'agesq']   # time constant explanatory varibles (not used in FE regressions)\n",
    "groupvar = 'id'                        # individual indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Object of interest\n",
    "We are interested in modeling\n",
    "$$\n",
    "P\\left(y_{it}=1|x_{it},c_{i}\\right) \n",
    "$$\n",
    "\n",
    "That is, the response probability - holding $x_{it}$ and $c_i$ constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A starting point: Linear Probability Model\n",
    "Linear unobserved effects model:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "P\\left( y_{it}=1|x_{it},c_{i}\\right) &=&E\\left[ y_{it}=1|x_{it},c_{i}\\right] \\\\\n",
    "&=&x_{it}\\beta +c_{i}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Problems are the usual ones:\n",
    "- $P\\left( y_{it}=1|x_{it},c_{i}\\right)$ not bounded between zero and one\n",
    "- $V\\left( y_{it}|x_{it},c_{i}\\right) $ depend on $x$ and $c_{i}$ (Heteroscedasticity)\n",
    "- ***and*** unnatural restrictions on $c_{i}$, $-x_{it}\\beta \\leq c_{i}\\leq 1-x_{it}\\beta $\n",
    "\n",
    "Advantages\n",
    "- Easy to remove $c_{i}$ (within transformation, FD, etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameter Estimates - Linear Fixed Effects Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Specification: Linear Fixed Effects Regression\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "kids           -0.0389      0.0092     -4.2435\n",
      "lhinc          -0.0089      0.0046     -1.9469\n",
      "per2           -0.0043      0.0034     -1.2586\n",
      "per3           -0.0109      0.0042     -2.6034\n",
      "per4           -0.0123      0.0045     -2.7389\n",
      "per5           -0.0177      0.0049     -3.6429\n",
      "# of groups:       5663\n",
      "# of observations: 28315 \n",
      "\n",
      "\n",
      "Specification: Pooled OLS Panel Regression\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "kids           -0.0679      0.0050    -13.5242\n",
      "lhinc          -0.0645      0.0067     -9.6000\n",
      "per2           -0.0024      0.0037     -0.6350\n",
      "per3           -0.0091      0.0045     -2.0335\n",
      "per4           -0.0130      0.0047     -2.7487\n",
      "per5           -0.0169      0.0051     -3.3310\n",
      "educ            0.0267      0.0021     12.6252\n",
      "black           0.0718      0.0199      3.6047\n",
      "age             0.0544      0.0029     18.9785\n",
      "agesq          -0.0007      0.0000    -20.0756\n",
      "# of groups:       5663\n",
      "# of observations: 28315 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column 1 in table 15.3 Wooldridge (p. 623)\n",
    "lpm_fe=lpd.estim(df, y_it, xvar=x_it+x_t , groupvar='id', method='fe', cov_type='robust')\n",
    "lpm_pols=lpd.estim(df, y_it, xvar=x_it+x_t+x_i, groupvar='id', method='pols', cov_type='robust')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Index models without unobserved effects\n",
    "Assume no unobserved effect\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{it}\\right) =G\\left( x_{it}\\beta \\right) ,t=1,2,...,T%\n",
    "$$\n",
    "\n",
    "We have not nearly assumed enough to obtain joint distribution of $\n",
    "y_{i}=\\{y_{i1},..,y_{iT}\\}$ given $x_{i}=\\{x_{i1},..,x_{iT}\\}$\n",
    "\n",
    "- Example:$\\ y_{i}|x_{i}$ could be serially correlated\n",
    "- **We need more assumptions to use CMLE!**\n",
    "\n",
    "Could we use another estimator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimator: Partial MLE\n",
    "\n",
    "Readings: Partial MLE (Wooldridge 13.8)\n",
    "\n",
    "We can obtain a $\\sqrt{N}$ consistent estimator of $\\beta $ by maximizing *partial* likelihood\n",
    "\n",
    "$$\n",
    "\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{t=1}^{T}\\left \\{ \\underset{\\ell _{it}\\left(\n",
    "y_{i}|x_{i};\\beta \\right) }{\\underbrace{y_{it}\\ln \\left( G\\left( x_{it}\\beta\n",
    "\\right) \\right) +\\left( 1-y_{it}\\right) \\ln \\left( 1-G\\left( x_{it}\\beta\n",
    "\\right) \\right) }}\\right \\} \n",
    "$$\n",
    "\n",
    "Note that $\\hat{\\beta}_{PML}$ *is clearly an M-estimator*\n",
    "\\begin{eqnarray*}\n",
    "\\hat{\\beta}_{PML} &=&\\arg \\min_{\\beta \\in \\Theta }\\frac{1}{N}\n",
    "\\sum_{i=1}^{N}q\\left( y_{i}|x_{i};\\beta \\right) \\text{, where} \\\\\n",
    "q\\left( y_{i}|x_{i};\\beta \\right) &=&-\\sum_{t=1}^{T}\\ell _{it}\\left(\n",
    "y_{i}|x_{i};\\beta \\right) \n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def Q_pooled(y, x, T, beta, model='probit', out='Q'):\n",
    "    ''' Pooled linear index model for panel data. e.g pooled probit or logit\n",
    "        y:      Nobs x 1 np.array of binary response data\n",
    "        x:      Nobs x k np.array of explanatory variables\n",
    "        T:      n x 1  np.array of containing number of time observations for each group \n",
    "        model:  'probit' or 'logit'\n",
    "        out:    controls what is returned - can be 'predict','Q', 'dQ', 's_i', or 'H'\n",
    "    '''\n",
    "\n",
    "    beta=np.array(beta).reshape(-1,1)             # parameters\n",
    "    n=T.shape[0];                                 # number of groups\n",
    "    xb=x @ beta                                   # Linear index \n",
    "    Gx=G(xb, model)                               # Response probability at x\n",
    "    gx=g(xb, model)                               # Density at xb\n",
    "    Gx=np.minimum(np.maximum(Gx,1e-15),1-1e-15)   # Truncating Gx\n",
    "    if out=='predict':  return xb, Gx, gx         # Return predicted values\n",
    "\n",
    "    ll_it = np.log(Gx)*y + np.log(1-Gx)*(1-y)     # Nobsx1 vector of log-likelihood contributions for group i at time t\n",
    "    q_i= - sumby(ll_it, T)                        # nx1 vector of (negative) log-likelihood contributions \n",
    "    if out=='Q': return np.mean(q_i);             # Return Q: sample objective function to be minimized - negative of log-likelihood\n",
    "\n",
    "    # 1st order derivatives\n",
    "    s_it=gx*x*(y-Gx)/( Gx* (1-Gx))                # NobsxK array of derivatives of ll_it\n",
    "    s_i = sumby(s_it, T)                          # nxK array of derivatives of ll_i (transposed scores staked over i)\n",
    "    if out=='s_i': return s_i                     # Return s_i: nxK array with scores\n",
    "    if out=='dQ':  return -np.mean(s_i, axis=0);  # Return dQ: array of size K derivative of sample objective function\n",
    "\n",
    "    # 2nd order derivatives\n",
    "    H=(gx*x).T @(gx*x/(Gx* (1-Gx)))/n             # Analytical Hessian averaged over all groups i\n",
    "    # H=s_it.T@ s_it/n                            # Alternative: use product of gradient as Hessian approximation\n",
    "    if out=='H':    return H; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameter Estimates - Pooled Probit\n",
    "Column 2 in table 15.3 Wooldridge (p. 623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled probit\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "kids           -0.19891     0.01445   -13.76457    -0.00000    -0.06602\n",
      "lhinc          -0.21107     0.02159    -9.77522     0.00000    -0.07005\n",
      "per2           -0.01242     0.01034    -1.20178     0.00000    -0.00412\n",
      "per3           -0.03252     0.01168    -2.78368    -0.00000    -0.01079\n",
      "per4           -0.04610     0.01257    -3.66801    -0.00000    -0.01530\n",
      "per5           -0.05778     0.01242    -4.65278     0.00000    -0.01918\n",
      "educ            0.07969     0.00618    12.88540    -0.00000     0.02645\n",
      "black           0.22094     0.05933     3.72402    -0.00000     0.07333\n",
      "age             0.14492     0.01097    13.20588     0.00000     0.04810\n",
      "agesq          -0.00199     0.00014   -14.46445     0.00000    -0.00066\n",
      "const          -1.06445     0.22302    -4.77280    -0.00000    -0.35328\n",
      "\n",
      "# of groups:      : 5663\n",
      "# of observations : 28315\n",
      "# log-likelihood. : -16556.671043389644 \n",
      "\n",
      "Iteration info: 26 iterations, 33 evaluations of objective, and 33 evaluations of gradients\n",
      "Elapsed time: 4.0617 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pooled(df, yvar, xvar, groupvar, model='probit', cov_type='sandwich', deriv=1): \n",
    "    print('Pooled', model)\n",
    "    Nobs, k, n, T, y, x = panel_setup(df, yvar, xvar, groupvar)\n",
    "    Qfun     = lambda beta, out:  Q_pooled(y, x, T, beta, model, out)\n",
    "    res=M.estimation(Qfun, theta0=np.zeros((k,1)), deriv=deriv, cov_type=cov_type, parnames=xvar)\n",
    "    xb, Gx, gx = Qfun(res.theta_hat, out='predict')\n",
    "    APE=np.mean(gx)*res.theta_hat\n",
    "    res.update(dict(zip(['yvar', 'xvar', 'Nobs','k', 'n', 'T', 'APE'], [yvar, xvar, Nobs, k, n, T, APE])))\n",
    "    print_output(res)\n",
    "    return res\n",
    "res_pp=pooled(df, y_it, xvar=x_it+x_t+x_i + ['const'] , groupvar='id', model='probit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Properties of Partial MLE\n",
    "\n",
    "**Since $\\hat{\\beta}_{PML}$ is an M-estimator**\n",
    "- $\\hat{\\beta}_{PML}$ is consistent (if identified) - by theorem 12.2 \n",
    "- $\\hat{\\beta}_{PML}$ is asymptotic normal - by theorem 12.3\n",
    "\n",
    "\n",
    "**But objective function is not based a the conditional density of $y_{i}$ given $x_{i;}$**\n",
    "- Need to do inference using the methods of ch. 12 to take account for potential serial correlation\n",
    "- Variance-covariance matrix on the form, $A^{-1}BA^{-1}$, $A\\neq B$\n",
    "- Wald Statistics (12.63) and score statistics (12.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parnames      theta_hat        Ainv        Binv    sandwich\n",
      "----------  -----------  ----------  ----------  ----------\n",
      "kids           -0.19891     0.00725     0.00367     0.01445\n",
      "lhinc          -0.21107     0.01226     0.00702     0.02159\n",
      "per2           -0.01242     0.02390     0.06298     0.01034\n",
      "per3           -0.03252     0.02312     0.05302     0.01168\n",
      "per4           -0.04610     0.02311     0.05503     0.01257\n",
      "per5           -0.05778     0.02256     0.04868     0.01242\n",
      "educ            0.07969     0.00311     0.00157     0.00618\n",
      "black           0.22094     0.03163     0.01698     0.05933\n",
      "age             0.14492     0.00582     0.00312     0.01097\n",
      "agesq          -0.00199     0.00007     0.00004     0.00014\n",
      "const          -1.06445     0.12645     0.07970     0.22302\n"
     ]
    }
   ],
   "source": [
    "def avar(s_i, Ainv, cov_type ='sandwich'):\n",
    "    n, K=s_i.shape\n",
    "    B=s_i.T@ s_i/n \n",
    "    if cov_type=='Binv':        return la.inv(B)/n\n",
    "    if cov_type=='Ainv':        return Ainv/n;         \n",
    "    if cov_type=='sandwich':    return Ainv @ B @ Ainv/n\n",
    "\n",
    "se={'parnames':res_pp.xvar, 'theta_hat':res_pp.theta_hat}\n",
    "for cov_type in ['Ainv', 'Binv', 'sandwich']:\n",
    "    cov = avar(res_pp.s_i, res_pp.hess_inv, cov_type)\n",
    "    se[cov_type]=  np.sqrt(np.diag(cov))\n",
    "print(tabulate(se, headers=\"keys\",floatfmt=\"10.5f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What did we assume?\n",
    "\n",
    "1. No unobserved effects\n",
    "2. Linear Index structure \n",
    "\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{it}\\right) =G\\left( x_{it}\\beta \\right) \n",
    "$$\n",
    "\n",
    "3. A functional form for $G\\left( {}\\right)$. \n",
    "\t- For example: $G\\left( {}\\right) =\\Phi \\left( {}\\right) $ (Pooled Probit)\n",
    "\n",
    "- We will relax 1) later in this lecture\n",
    "\n",
    "- Semi/Non-parametric approaches can be used to relax 2) and 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What did we NOT assume?\n",
    "\n",
    "1. Dynamic Completeness\n",
    "\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{it},y_{it-1},x_{it-1},y_{it-2},....\\right) =P\\left(\n",
    "y_{it}=1|x_{it}\\right) \n",
    "$$\n",
    "\n",
    "2. Strict exogeneity (conditional on a unobserved effect)\n",
    "\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{i},c_{i}\\right) =P\\left( y_{it}=1|x_{it},c_{i}\\right) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Under dynamic completeness\n",
    "\n",
    "Dynamically complete models\n",
    "\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{it},y_{it-1},x_{it-1},y_{it-2},....\\right) =P\\left(\n",
    "y_{it}=1|x_{it}\\right) \n",
    "$$\n",
    "\n",
    "- We are not assuming independence ($x_{it}$ can contain lagged dependent variables)\n",
    "- Easier to justify when $x_{it}$ contains lagged values of $y_{it}$ and $x_{it}$\n",
    "- Does not imply independence: \n",
    "\t- $x_{it}$ can contain lagged dependent variables\n",
    "\t- But scores are independent across $t$\n",
    "- Inference is easier\n",
    "    - We can just treat the sample as one big cross-section of size $NT$\n",
    "\n",
    "    - Why: $A_{0}=B_{0}$ for PML when scores are serially uncorrelated (see 13.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Test for dynamic completeness\n",
    "\n",
    "1. Estimate artificial model and generate residuals \n",
    "$$\n",
    "\\hat{u}_{it}=y_{it}-G\\left( x_{it}\\hat{\\beta}\\right) \n",
    "$$\n",
    "\n",
    "2. Estimate model where residuals is included \n",
    "$$\n",
    "P\\left( y_{it}=1|x_{it},\\hat{u}_{it-1}\\right) =G\\left( x_{it}\\beta +\\gamma _{1}\\hat{u}_{it-1}\\right)\n",
    "$$\n",
    "\n",
    "3. Test $H_{0}:\\gamma _{1}=0$. \n",
    "\n",
    "If $H_{0}$ is rejected so is dynamic completeness.\n",
    "\n",
    "- This works because $u_{it}$ must uncorrelated with any function of \n",
    "$\\left\\{x_{it},y_{it-1},x_{it-1},y_{it-2}...\\right \\} $ including $u_{it-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unobserved Effects Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Unobserved Effects Models under Strict Exogeneity\n",
    "\n",
    "**Strict exogeneity (and index restriction) implies**\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "P\\left( y_{it}=1|x_{i},c_{i}\\right) &=&P\\left( y_{it}=1|x_{it},c_{i}\\right) \\\\\n",
    "&=&G\\left( x_{it}\\beta +c_{i}\\right) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "**Strict Exogeneity**\n",
    "- $x_{it}$ cannot include lagged dependent variables or explanatory variables with feedback from current and past values of $y_{it}$\n",
    "\n",
    "- Reason is completelely anologous to our previous discussion for the linear model\n",
    "\n",
    "**Problem: $c_{i}$ is unobserved**\n",
    "\n",
    "- We can not condition on $c_{i}$ (it is unobserved)\n",
    "- It cannot be differenced away - due to the nonlinearity of $G()$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to deal with unobserved effect?\n",
    "\n",
    "Some possibilities: \n",
    "\n",
    "1. **Estimate $c_{i}$** (treat as a parameter)\n",
    "\t- We can never consistently estimate $c_{i}$ for a given $T$\n",
    "\t- Incidental Parameters Problem}: $\\hat{\\beta}$ is not $\\sqrt{N}$-consistent for fixed $T$ (unlike in the linear case)\n",
    "\t- Need long panel to estimate $c_{i}$ (at least 7-10 observations for each individual)\n",
    "\n",
    "2. **Random Effects:** Assume distribution of $c_{i}|x_{i}$ and integrate out $c_{i}$.\n",
    "\t- How do we come up with a distribution \n",
    "\t- Example below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More possibilities\n",
    "\n",
    "3. **Fixed Effects:** Eliminate $c_{i}$ by transformation\n",
    "\t- We can not difference $c_{i}$ out - due to non-linearity\n",
    "\t- Not easy to find transformation (vary from model to model)\n",
    "\t- Example below\n",
    "\n",
    "4. **Pooled analysis**\n",
    "\t- if we are willing to assume particular random effects structure and interest is in $APE$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Effects: Assumptions\n",
    "\n",
    "Random Effects Linear Index Models\n",
    "1. Strict exogeneity (and index structure)\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{i},c_{i}\\right) =G\\left( x_{it}\\beta +c_{i}\\right) \n",
    "$$\n",
    "2. Independence of $y_{i1},..,y_{iT}$ conditional on $\\left(x_{i},c_{i}\\right)$\n",
    "implies that : $f\\left( y_{1},..,y_{T}|x_{i},c;\\beta \\right)=\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c,\\beta \\right) $\n",
    "\n",
    "3. Normality of $c_{i}|x_{i}$\n",
    "$$\n",
    "c_{i}|x_{i}\\sim N\\left( 0,\\sigma _{c}^{2}\\right) \n",
    "$$\n",
    "Implies: $c_{i}$ and $x_{i}$ are independent and that $c_{i}$ has a normal distribution\n",
    "\n",
    "Alternative to 3): Discrete support for $c_{i}$ and independence between $x_{i}$ and $c_{i}$\n",
    "\n",
    "Under these assumptions we can estimate model with CMLE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Effects: Discrete support \n",
    "Joint distribution of $y_{i}|x_{i}$\n",
    "$$\n",
    "f\\left( y_{1},..,y_{T}|x_{i};\\theta \\right) =\\sum_{j}\\pi\n",
    "^{j}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c^{j},\\beta \\right) \n",
    "$$\n",
    "where \n",
    "$$\n",
    "f(y_{t}|x_{it},c,\\beta) =  y_{t}G(x_{it}\\beta +c) + (1-y_{t}) [ 1-G(x_{it}\\beta +c)]\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\sum_{j}\\pi ^{j}=1\\text{  and }\\sum_{j}\\pi ^{j}c^{j}=0\n",
    "$$\n",
    "\n",
    "NOTE: $\\pi ^{j}$ and $c^{j}$ are parameters to be estimated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Effects: Discrete Support\n",
    "**Examble with 2 support points: $c^{l}$ and $c^{h}$**\n",
    "Joint distribution of $y_{i}|x_{i}$\n",
    "\\begin{eqnarray*}\n",
    "f\\left( y_{1},..,y_{T}|x_{i};\\theta \\right) &=&\\pi^{l}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c^{l},\\beta \\right) \\\\\n",
    "&&+\\left( 1-\\pi ^{l}\\right) \\prod_{t=1}^{T}f\\left( y_{t}|x_{it},-\\pi^{l}/\\left( 1-\\pi ^{l}\\right) c^{l},\\beta \\right) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "Two additional parameters to be estimated\n",
    "- Probability of being a low type, $\\pi$\n",
    "- Support point for low type, $c^{l}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Effects: Normally Distributed $c_i$\n",
    "\n",
    "Joint distribution of $y_{i}|x_{i}$\n",
    "\n",
    "$$\n",
    "f\\left( y_{1},..,y_{T}|x_{i};\\theta \\right) =\\int_{-.\\infty }^{\\infty\n",
    "}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c,\\beta \\right) \\frac{1}{\\sigma _{c}}%\n",
    "\\phi \\left( c/\\sigma _{c}\\right) dc\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "f\\left( y_{t}|x_{it},c,\\beta \\right) = y_{t}G\\left( x_{it}\\beta +c\\right) +\n",
    "\\left( 1-y_{t}\\right) \\left[ 1-G\\left( x_{it}\\beta +c\\right) \\right]\n",
    "$$\n",
    "\n",
    "**How to evaluate integral?**\n",
    "\n",
    "1. Gaussian Quadrature\n",
    "(for example Gauss-Hermite quadrature for integrals on the form $\\int_{-.\\infty}^{\\infty }h\\left( z\\right) \\exp \\left( -z^{2}\\right) dz$)\n",
    "2. Simulation (The integrals equivalent to take expectations over random variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RECAP: Gaussian quadrature\n",
    "\n",
    "General formula\n",
    "\n",
    "$$\n",
    "\\int_a^b f(x)w(x) dx = \\sum_{i=1}^n \\omega_i f(x_i) + \\text{approximation error}\n",
    "$$\n",
    "\n",
    "- $w(x)$ non-negative weighting function\n",
    "- $ x_i \\in [a,b] $ quadrature nodes  \n",
    "- $ \\omega_i $ quadrature weights\n",
    "- Nodes and weights are chosen so that there is no approximation error if $f(x)$ belongs to the family of $2n-1$ degree polynomials\n",
    "- Choice of method differ by weighting function $w(x)$ and domain $[a, b]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussian quadrature\n",
    "$$\n",
    "\\int_a^b f(x)w(x) dx = \\sum_{i=1}^n \\omega_i f(x_i) + \\text{approximation error}\n",
    "$$\n",
    "\n",
    "- Gauss-Legendre Quadrature ($w(x)=1$, domain $[a, b]$)\n",
    "- Gauss-Chebyshev Quadrature ($w(x)=(1-x^2)^{(-1/2)} $, domain  $[a, b]$)\n",
    "- Gauss-Hermite Quadrature ($w(x)=\\exp(−𝑥^2)$, domain  $[-\\infty, \\infty]$)\n",
    "- Gauss-Laguerre Quadrature ($w(x)=\\exp(−𝑥)$, domain  $[a, \\infty]$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gauss-Legendre Quadrature\n",
    "\n",
    "- Domain $ [-1,1]$ .. or   $[a,b]$\n",
    "- Weighting $ 1 $  \n",
    "\n",
    "\n",
    "$$\n",
    "\\int_{-1}^1 f(x) dx = \\sum_{i=1}^{n} \\omega_i f(x_i) + \\frac{2^{2n+1}(n!)^4}{(2n+1)!(2n)!}\\frac{f^{(2n)}(\\xi)}{(2n)!}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Nodes and weights come from Legendre polynomials, values tabulated  \n",
    "- Good for computing expectation of random variables with finite support.\n",
    "- Can also be used for computing expectation if transforming using inverse CDF (has domain [0,1]]\n",
    "- The method of choice when no obvious weighting function can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Change of variable for Gauss-Legendre\n",
    "A linear change of variable is nessesary to apply Gauss-Legendre quadrature to general intervals $[a, b]$ rather than $[−1, 1]$ \n",
    "\n",
    "This change of interval from $[a, b]$ to $[−1, 1]$ can be done in the following way:\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\int _{a}^{b}f(x)\\,dx={\\frac {b-a}{2}}\\int _{-1}^{1}\n",
    "f\\left({\\frac {(x+1)(b-a)}{2} +a }\\right)\\,dx .}\n",
    "$$\n",
    "\n",
    "Applying n point Gaussian quadrature ${\\displaystyle (x ,w)}$ rule then results in the following approximation:\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\int _{a}^{b}f(x)\\,dx\\approx {\\frac {b-a}{2}}\\sum _{i=1}^{n}w_{i}\n",
    "f\\left({\\frac {(x_i+1)(b-a)}{2} +a }\\right)\\,dx .}\n",
    "%f\\left({\\frac {b-a}{2}}x _{i}+{\\frac {a+b}{2}}\\right).}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approximation of joint distribution of $y_{i}|x_{i}$ using Gauss-Legendre\n",
    "We can reformulate the integral by making the simple change of variable \n",
    "$$c_i=\\sigma _{c}\\Phi^{-1}(q_i)$$ \n",
    "where $q_i$ is now uniformly rather than normally distributed\n",
    "\n",
    "We get\n",
    "\\begin{eqnarray*}\n",
    "f\\left( y_{1},..,y_{T}|x_{i};\\theta \\right) \n",
    "&=&\\int_{-.\\infty }^{\\infty}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c,\\beta \\right) \\frac{1}{\\sigma _{c}}\\phi \\left( c/\\sigma _{c}\\right) dc \\\\\n",
    "&=&\\int_{0}^{1}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},\\sigma _{c}\\Phi^{-1}(q),\\beta \\right) dq\n",
    "\\end{eqnarray*}\n",
    "This integral is easily approximated by Gauss-Legendre quadrature \n",
    "$$\n",
    "\\int_{0}^{1}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},\\sigma _{c}\\Phi^{-1}(q),\\beta \\right) dq \\approx\n",
    "\\sum_{j=1}^{m}w_j\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},\\sigma _{c}\\Phi^{-1}(q_j),\\beta \\right)=\n",
    "\\sum_{j=1}^{m}w_j f(q_j)\n",
    "$$\n",
    "where $w_j$ and $q_j$ are Gauss-Legendre weights and nodes for adjusted to the interval $[0,1]$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def Q_RE(y, x, T, theta, model='probit', out='Q', R=20, rng=random.default_rng(seed=11)):\n",
    "    ''' Pooled linear index model for panel data. e.g pooled probit or logit\n",
    "        y:      Nobs x 1 np.array of binary response data\n",
    "        x:      Nobs x k np.array of explanatory variables\n",
    "        T:      n x 1  np.array of containing number of time observations for each group \n",
    "        model:  'probit' or 'logit'\n",
    "        out:    controls what is returned - can be 'predict','Q', 'dQ', 's_i', or 'H'\n",
    "    '''\n",
    "    Nobs, k= x.shape\n",
    "    n=T.shape[0];                                 # number of groups\n",
    "\n",
    "    sigma_a=theta[-1]                             # heterogeneity parameter\n",
    "    beta=np.array(theta[:-1]).reshape(-1,1)       # slope parameters\n",
    "    \n",
    "    xb=x @ beta                                   # Linear index \n",
    "    gx=g(xb, model)                               # Density at xb\n",
    "    Gx=G(xb).reshape(-1,1)\n",
    "    if out=='predict':  return xb, Gx, gx         # Return predicted values\n",
    "\n",
    "    # compute alpha for used sample objective function at Legendre quadrature nodes\n",
    "    q,w=quad_xw(R, a=0, b=1)\n",
    "    q=q.reshape(1,R)\n",
    "    w=w.reshape(1,R)\n",
    "    eta=norm.ppf(q);\n",
    "    alpha=sigma_a*eta\n",
    "\n",
    "    G_itq=G(xb + alpha, model)                          # Reponse probability at x for each quadrature point (Nobs x R)\n",
    "    G_itq=np.minimum(np.maximum(G_itq,1e-15),1-1e-15)   # Truncating G\n",
    "    F_itq = G_itq*y + (1-G_itq)*(1-y)                   # Nobsx1 vector of log-likelihood contributions for group i at time t\n",
    "    F_iq  = prodby(F_itq,T)                             # product over time, n by R\n",
    "    Fi = np.sum(F_iq*w, axis=1).reshape(-1,1)           # sum over quad/sims, n by 1 (likelihood contribution for unit i)\n",
    "    q_i= - np.log(Fi)                                   # nx1 vector of (negative) log-likelihood contributions \n",
    "    if out=='Q': return np.mean(q_i);                   # Return Q: sample objective function to be minimized - negative of log-likelihood\n",
    "\n",
    "    # 1st order derivatives\n",
    "    g_itq=g(xb + alpha, model)\n",
    "    s_itq=g_itq*(y-G_itq)/(G_itq*(1-G_itq)) # Nobs x R\n",
    "    n_p=theta.shape[0]\n",
    "    s_i=np.empty((n, n_p))                          # nxK+1 array of derivatives of ll_i (transposed scores staked over i)\n",
    "    for ip in range(n_p-1):\n",
    "        dw_iq=sumby(s_itq*x[:,ip].reshape(-1,1), T);  # n x R \n",
    "        s_i[:,ip]=np.sum(w*F_iq*dw_iq/Fi.reshape(-1,1),axis =1)  # sum over quad/sim points\n",
    "    dw_iq=sumby(s_itq*eta, T);  # n x R \n",
    "    s_i[:,-1]=np.sum(w*F_iq*dw_iq/Fi,axis =1)       \n",
    "    if out=='s_i': return s_i                       # Return s_i: nxK array with scores\n",
    "    if out=='dQ':  return -np.mean(s_i, axis=0);    # Return dQ: array of size K derivative of sample objective function\n",
    "\n",
    "    # 2nd order derivatives\n",
    "    H=s_i.T@ s_i/n                                  # Alternative: use product of gradient as Hessian approximation\n",
    "    if out=='H':    return H; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gauss-Hermite Quadrature\n",
    "\n",
    "- Domain $ [-\\infty,\\infty] $  \n",
    "- Weighting $ \\exp(-x^2) $  \n",
    "\n",
    "\n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} f(x) \\exp(-x^2)dx = \\sum_{i=1}^{n} f(x_i) + \\frac{n!\\sqrt{\\pi}}{2^n}\\frac{f^{(2n)}(\\xi)}{(2n)!}\n",
    "$$\n",
    "\n",
    "- Nodes and weights come from Hermite polynomials, values tabulated  \n",
    "- Good for computing expectation with Normal distribution \n",
    "$$\n",
    "E[f(y)]\n",
    "=(2\\pi\\sigma^2)^{-1/2}\\int_{-\\infty}^{\\infty} f(y)e^{-(y-\\mu)^2/(2\\sigma^2)}dy\n",
    "$$\n",
    "\n",
    "since normal density is proportional to $\\exp(-x^2)$ after  appropriate change of variable $x=(y-\\mu)/(\\sqrt{2}\\sigma)$ so that $y=\\sqrt{2}\\sigma x+ \\mu$ and $dy=\\sqrt{2}\\sigma dx$\n",
    "$$\n",
    "E[f(y)]\n",
    "=\\pi^{-1/2}\\int_{-\\infty}^{\\infty} f(\\sqrt{2}\\sigma x+ \\mu)e^{-x^2}dx\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approximation of joint distribution of $y_{i}|x_{i}$ using Gauss-Hermite\n",
    "We have an integral on this form\n",
    "\\begin{eqnarray*}\n",
    "&&\\int_{-.\\infty }^{\\infty }\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c,\\beta\n",
    "\\right) \\frac{1}{\\sigma _{c}}\\phi \\left( c/\\sigma _{c}\\right) dc \\\\\n",
    "&=&\\pi^{-1/2}\\int_{-.\\infty }^{\\infty }\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},z\\sqrt{2\\sigma _{c}^{2}},\\beta \\right) \\exp \\left(-z^{2}\\right)dz\\\\\n",
    "&=&\\int_{-.\\infty }^{\\infty }h\\left( z\\right) \\exp \\left( -z^{2}\\right) dz \\cong \\sum_{j}w_{j}h\\left( z_{j}\\right)\\\\\n",
    "&=&\\pi^{-1/2}\\sum_{j=1}^{m}w_j\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},z_j\\sqrt{2\\sigma _{c}^{2}},\\beta \\right)\\\\\n",
    "\\end{eqnarray*}\n",
    "where \n",
    "- $w_{j}$ are Hermite quadrature weights\n",
    "- $z_{j}$ are Hermite quadrature nodes\n",
    "- The more nodes - The higher the precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Effects: Maximum Simulated Likelihood Estimation\n",
    "\n",
    "Simulation Likelihood contribution individual $i$\n",
    "1. Take $R$ independent draws from the standard normal label them $\\eta^{r},$ $r=1,..,R$\n",
    "2. Compute $c_{i}^{r}=\\sigma _{c}\\eta ^{r}$\n",
    "3. Compute $\\prod_{t=1}^{T}f\\left( y_{it}|x_{it},c^{r},\\beta \\right) $ for each $r$\n",
    "3. Average the results and take logs \n",
    "$$\n",
    "\\hat{\\ell}_{i}\\left( \\theta \\right)=\\ln \\frac{1}{R}\\sum_{i=1}^{R}\\prod_{t=1}^{T}f\\left(\n",
    "y_{it}|x_{it},c^{r},\\beta \\right) \n",
    "$$\n",
    "\n",
    "**Estimation:**\n",
    "Maximize sample average of log of simulated likelihood w.r.t. $\\theta=\\left\\{ \\beta ,\\sigma _{c}^{2}\\right \\}$\n",
    "$$\n",
    "\\hat{\\theta}_{MSL}=\\arg \\max_{\\theta =\\left \\{ \\beta ,\\sigma _{c}^{2}\\right\\} }\\frac{1}{N}\\sum_{i=1}^{N}\\ln\\frac{1}{R}\\sum_{i=1}^{R}\\prod_{t=1}^{T}f\\left( y_{it}|x_{it},c^{r},\\beta \\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Remarks on Simulated Based Estimation\n",
    "\n",
    "Properties of MSL\n",
    "1. If R is fixed, MSL is inconsistent.\n",
    "2. If R rises slower than$\\sqrt{N}$, MSL is consistent but not asymptotically normal.\n",
    "3. If R rises faster than $\\sqrt{N}$, MSL is consistent, asymptotically normal and efficient, and equivalent to MLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to relax assumptions on unobserved effect within random effects framework?\n",
    "\n",
    "We can relax assumptions by re-specifying model\n",
    "- Serial correlation: Requires evaluation of $T$ dimensional integrals (use simulation methods)\n",
    "- Chamberlain approach: Specified correlation with $x_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fixed Effects Logit\n",
    "\n",
    "**The trick:**\n",
    "- Model the joint distribution of $y_{i}$ conditional on $x_{i}$, $c_{i}$ *and* $n_{i}=\\sum_{i}y_{it}$\n",
    "- In the logit model, it turns out that this does not depend on $c_{i}.$\n",
    "- For $T=2$ we have\n",
    "\\begin{eqnarray*}\n",
    "P\\left( y_{i2}=1|x_{i},c_{i},n_{i}=1\\right) &=&\\Lambda \\left( \\left(x_{i2}-x_{i1}\\right) \\beta \\right) \\\\\n",
    "P\\left( y_{i1}=1|x_{i},c_{i},n_{i}=1\\right) &=&1-\\Lambda \\left( \\left(\n",
    "x_{i2}-x_{i1}\\right) \\beta \\right) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "$$\n",
    "l_{i}\\left( \\beta \\right) =\\left(n_{i}=1\\right) \\left \\{ \n",
    "\\begin{array}{c} \n",
    "w_{i}\\Lambda \\left( \\left( x_{i2}-x_{i1}\\right) \\beta \\right) + \\\\ \n",
    "\\left( 1-w_{i}\\right) \\left( 1-\\Lambda \\left( \\left( x_{i2}-x_{i1}\\right) \\beta \\right) \\right)\n",
    "\\end{array}\n",
    "\\right \\} \n",
    "$$\n",
    "- NOTE: We cannot use this trick eliminate $c_{i}$ in the probit model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fixed Effects Logit: Identification\n",
    "Identification:\n",
    "- Conditional distribution of $y_{it}$ is not informative about $\\beta $, when $n_{i}=0$ or $n_{i}=T$ \n",
    "(since $n_{i}=0$ and $n_{i}=2$ perfectly predict $y_{it}$)\n",
    "- We therefore need time-series variation in $y_{it}$ to identify $\\beta $\n",
    "\n",
    "**Identified objects**\n",
    "- We can identify $\\beta$ (up to scale) and obtain the effect on the log-odd ratio:\n",
    "$$\n",
    "\\ln \\left[ \\frac{\\left( \\Lambda \\left( x_{t}^{\\prime }\\beta \\right) \\right) \n",
    "}{\\left( 1-\\Lambda \\left( x_{t}^{\\prime }\\beta \\right) \\right) }\\right] = x_{t}^{\\prime }\\beta +c%\n",
    "$$\n",
    "\n",
    "**Unidentified objects**\n",
    "- Partial effects cannot be estimated unless we assume *value* of $c$\n",
    "- $APE$ can't be estimated - since we do not assume *distribution* of $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simulation exercise\n",
    "Model \n",
    "\\begin{eqnarray*}\n",
    "y_{it}&=&1(z_{it} \\delta + \\rho y_{it-1} + c_i +e_{it}>0)\\\\\n",
    "c_i   &=& \\phi_0 + \\phi_{y0} y_{i0} + a_i\\\\\n",
    "a_i &\\sim&  iidN(0, \\sigma_a^2)\\\\\n",
    "e_{it} &\\sim& iidN(0, 1)\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       group  period    y         z   y0  const  l1.y\n",
      "1        0.0     1.0  1.0  0.678178  1.0    1.0   1.0\n",
      "2        0.0     2.0  1.0 -0.585529  1.0    1.0   1.0\n",
      "3        0.0     3.0  1.0 -0.908673  1.0    1.0   1.0\n",
      "4        0.0     4.0  0.0 -1.991838  1.0    1.0   1.0\n",
      "5        0.0     5.0  0.0  0.971623  1.0    1.0   0.0\n",
      "...      ...     ...  ...       ...  ...    ...   ...\n",
      "10995  999.0     6.0  0.0 -0.754210  0.0    1.0   0.0\n",
      "10996  999.0     7.0  0.0 -0.985524  0.0    1.0   0.0\n",
      "10997  999.0     8.0  1.0  1.078294  0.0    1.0   0.0\n",
      "10998  999.0     9.0  1.0  0.750458  0.0    1.0   1.0\n",
      "10999  999.0    10.0  1.0  2.052021  0.0    1.0   1.0\n",
      "\n",
      "[10000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from indexmodels import *\n",
    "df_sim=simulate(n=1000, nT=10, model='probit', rho=1, delta=1, phi_0=0, phi_y0=0, sigma_a=1)\n",
    "print(df_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Experiments - static models\n",
    "1. No heterogeneity \n",
    "    - does LPM give a good approximation of APE\n",
    "    - does pooled probit estimate true parameters\n",
    "    \n",
    "1. Neglect heterogeneity - Pooled probit or LPM\n",
    "   - does pooled probit estimate true parameters?\n",
    "   - does pooled OLS and probit still estimate APE\n",
    "\n",
    "1. Can RE-Probit estimate account for heterogeneity and uncover true parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Specification: Pooled OLS Panel Regression\n",
      "Dep. var. : y \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "z               0.1665      0.0052     32.2766\n",
      "const           0.4958      0.0112     44.3676\n",
      "# of groups:       1000\n",
      "# of observations: 10000 \n",
      "\n",
      "\n",
      "Specification: Linear Fixed Effects Regression\n",
      "Dep. var. : y \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "z               0.1664      0.0046     36.1068\n",
      "# of groups:       1000\n",
      "# of observations: 10000 \n",
      "\n",
      "Pooled probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               0.45785     0.01700    26.92896     0.00000     0.16634\n",
      "const          -0.01123     0.03076    -0.36507     0.00000    -0.00408\n",
      "\n",
      "# of groups:      : 1000\n",
      "# of observations : 10000\n",
      "# log-likelihood. : -6355.062021375215 \n",
      "\n",
      "Iteration info: 4 iterations, 5 evaluations of objective, and 5 evaluations of gradients\n",
      "Elapsed time: 0.2140 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta=1; sigma_a=2\n",
    "df_sim=simulate(n=1000, nT=10, model='probit', delta=delta, sigma_a=sigma_a, phi_y0=0)\n",
    "lpm_ols=lpd.estim(df_sim, 'y', xvar=['z', 'const'], groupvar='group', method='pols', cov_type='robust')\n",
    "lpm_fe=lpd.estim(df_sim, 'y',  xvar=['z'], groupvar='group', method='fe', cov_type='robust')\n",
    "res_pp=pooled(df_sim, 'y', xvar =['z', 'const'] , groupvar='group', model='probit', cov_type='sandwich')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neglegted heterogeneity in pooled probit\n",
    "- Recall that we only estimate parameters up to a scale, $\\beta/\\sigma$,  where $\\sigma^2$ is the variance on the error component in the latent variable formulation. \n",
    "- To obtain identification for probit we normalize $\\sigma^2$ to one\n",
    "- We have two errors $v_{it}=a_i + e_{it}$ whose variance is $1+\\sigma_a^2$\n",
    "- So what we have estimated is $\\beta/\\sigma=\\beta/\\sqrt{1+\\sigma_a^2}$\n",
    "- Pooled probit consistently estimates $P(y_{it}|x_{it})=\\Phi({x\\beta/\\sigma})$ and average partial effect $E_c(\\beta/\\sigma \\phi(x\\beta+c))=E(\\beta/\\sigma \\phi(x\\beta/\\sigma))$\n",
    "- Is neglected heterogeneity a problem in static models?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               0.43447     0.01684    25.80177     0.00000     0.15896\n",
      "const          -0.00487     0.03110    -0.15652    -0.00005    -0.00178\n",
      "\n",
      "# of groups:      : 1000\n",
      "# of observations : 10000\n",
      "# log-likelihood. : -6396.414325386091 \n",
      "\n",
      "Iteration info: 3 iterations, 4 evaluations of objective, and 4 evaluations of gradients\n",
      "Elapsed time: 0.1765 seconds\n",
      "\n",
      "true delta                     : 1\n",
      "delta_hat - pooled probit      : 0.43447412161118665\n",
      "delta/(np.sqrt(1+sigma_a**2))  : 0.4472135954999579\n"
     ]
    }
   ],
   "source": [
    "df_sim=simulate(n=1000, nT=10, model='probit', delta=1, sigma_a=2, phi_y0=0)\n",
    "res_pp=pooled(df_sim, 'y', xvar =['z', 'const'] , groupvar='group', model='probit', cov_type='sandwich')\n",
    "print('true delta                     :' , delta)\n",
    "print('delta_hat - pooled probit      :' , res_pp.theta_hat[0,0])\n",
    "print('delta/(np.sqrt(1+sigma_a**2))  :' , delta/np.sqrt(1+sigma_a**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Can RE-Probit estimate account for heterogeneity and uncover true parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               0.71727     0.01473    48.71043    -0.00000     0.23244\n",
      "const          -0.01908     0.00734    -2.60025    -0.00000    -0.00618\n",
      "\n",
      "# of groups:      : 1000\n",
      "# of observations : 10000\n",
      "# log-likelihood. : -5709.944071058581 \n",
      "\n",
      "Iteration info: 4 iterations, 5 evaluations of objective, and 5 evaluations of gradients\n",
      "Elapsed time: 0.2503 seconds\n",
      "\n",
      "Random effects probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               1.01117     0.02374    42.59992     0.00000     0.23307\n",
      "const          -0.02791     0.03520    -0.79296    -0.00000    -0.00643\n",
      "sigma_a         0.98536     0.03438    28.66144    -0.00000     0.22712\n",
      "\n",
      "# of groups:      : 1000\n",
      "# of observations : 10000\n",
      "# log-likelihood. : -4899.601136463136 \n",
      "\n",
      "Iteration info: 7 iterations, 8 evaluations of objective, and 8 evaluations of gradients\n",
      "Elapsed time: 0.8817 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sim=simulate(n=1000, nT=10, model='probit', delta=1, sigma_a=1, phi_y0=0)\n",
    "res_rep=pooled(df_sim, 'y', xvar =['z', 'const'] , groupvar='group', model='probit', cov_type='Binv')\n",
    "res_rep=rand_effect(df_sim, 'y', xvar =['z', 'const'] , groupvar='group', model='probit', cov_type='Binv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dynamic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dynamic Unobserved Effects Models\n",
    "\n",
    "**Dynamic model**\n",
    "\n",
    "$$\n",
    "P\\left( y_{it}=1|y_{it-1},y_{it-2},....,y_{i0},z_{i},c_{i}\\right) =G\\left(\n",
    "z_{it}\\delta +\\rho y_{it-1}+c_{i}\\right) \n",
    "$$\n",
    "\n",
    "\n",
    "- Particular interest is in coefficient on lagged dependent variable (state dependence)\n",
    "- $z_{it}$ is strictly exogenous\n",
    "\n",
    "**Spurious state dependence**\n",
    "- Note that even if $\\rho=0$ we have \n",
    "$$\n",
    "P\\left( y_{it}=1|y_{it-1},z_{i}\\right) \\ne P\\left( y_{it}=1|z_{i}\\right)\n",
    "$$\n",
    "- This is due to the presence of $c_i$ \n",
    "- *Important to appropriately control for $c_{i}$**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to deal with unobserved effect\n",
    "Joint density for $y_t$ for periods $1$ to $T$, conditional on $z_t$, $c$ and $y_0$\n",
    "\\begin{eqnarray*}\n",
    "f\\left(y_{1},..,y_{T}|z, c, y_0;\\beta \\right) \n",
    "&=& \\prod_{t=1}^{T}f\\left( y_{t}|y_{t-1},\\dots y_0, z_{t},c,\\beta \\right) \\\\\n",
    "&=& \\prod_{t=1}^{T}\n",
    "G\\left(z_{t}\\delta +\\rho y_{t-1}+c\\right)^{y_{t}} \n",
    "\\left[ 1-G\\left(z_{t}\\delta +\\rho y_{t-1}+c   \\right) \\right]^{1-y_{t}}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "1. **Estimate $c_{i}$ ?**\n",
    "\t- **NO:** Incidental parameters problem is even more severe in dynamic models (Heckman 1981)\n",
    "    \n",
    "2. **Dynamic Random Effects Model**\n",
    "\t- Integrate out $c_{i}$\n",
    "\t- Initial condition problem: $c_{i}$ is likely to be correlated with initial conditions $y_{i0}$\n",
    "    - Otherwise, if $\\rho>0$ $c_i$ is correlated with $y_i$ for all other periods than $t=0$ (VERY unrealistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to deal initial conditions problem\n",
    "**Several approaches**\n",
    "1. Treat $y_{i0}$ as non-random, i.e. assume independence between $y_{i0}$ and $c_{i}$ (*very* strong assumption)\n",
    "2. Wooldridge/Chamberlain approach: \n",
    "\t- Assume distribution for $c|y_{0};z$ \n",
    "\t- Leading example: $N\\left( \\psi +\\xi _{0}y_{i0}+z_{i}\\xi ,\\sigma_{a}\\right) $\n",
    "\t- Approximation of distribution for $y_{i0}|z_{i},c_{i}$ (Heckman, 1981)\n",
    "3. Semiparametric approaches \n",
    "\t- in a model with fixed effects (Honoré and Kyriazidou, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A simple solution to initial conditions in the probit model\n",
    "**Chamberlain/Wooldridge approach:**\n",
    "\n",
    "Assume \n",
    "$$\n",
    "c|y_{0};z\\sim N\\left( \\psi +\\xi _{0}y_{i0}+z_{i}\\xi ,\\sigma _{a}\\right) \n",
    "$$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "c_{i} &=&\\psi +\\xi _{0}y_{i0}+z_{i}\\xi +a_{i} \\\\\n",
    "a_{i} &\\sim &N\\left( 0,\\sigma _{a}\\right) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "For the probit model, $G\\left( {}\\right) =\\Phi \\left( {}\\right) $ we have latent variable form\n",
    "\\begin{eqnarray*}\n",
    "y_{it} &=&1\\left[ z_{it}\\delta +\\rho y_{it-1}+c_{i}+e_{it}\\right] \\\\\n",
    "&=&1\\left[ z_{it}\\delta +\\rho y_{it-1}+\\psi +\\xi _{0}y_{i0}+z_{i}\\xi+a_{i}+e_{it}\\right] \n",
    "\\end{eqnarray*}\n",
    "where $e_{it}\\sim N\\left( 0,1\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A simple solution to initial conditions in the probit model\n",
    "\n",
    "**Chamberlain/Wooldridge approach:**\n",
    "\n",
    "Recall the estimating equation\n",
    "\n",
    "$$\n",
    "y_{it}=1\\left[ z_{it}\\delta +\\rho y_{it-1}+\\psi +\\xi _{0}y_{i0}+z_{i}\\xi+a_{i}+e_{it}\\right] \n",
    "$$\n",
    "\n",
    "- This equation can be estimated by a standard random effects probit\n",
    "- Simply add $y_{i0}$ and $z_{i}$ to the conditioning set to take account of\n",
    "\t1. initial conditions problem\n",
    "\t2. specified correlation between $c_{i}$ and $z_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simulation exercise\n",
    "Model \n",
    "\\begin{eqnarray*}\n",
    "y_{it}&=&1(z_{it} \\delta + \\rho y_{it-1} + c_i +e_{it}>0)\\\\\n",
    "c_i   &=& \\phi_0 + \\phi_{y0} y_{i0} + a_i\\\\\n",
    "a_i &\\sim&  iidN(0, \\sigma_a^2)\\\\\n",
    "e_{it} &\\sim& iidN(0, 1)\n",
    "\\end{eqnarray*}\n",
    "- I apologize for yet another almost unforgivable ZIG-ZAG  and abuse of notation. Notion on this slide attempts to match code and experiments below ... not the notation in presentation above that attempts to follow Wooldridge. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Experiments - dynamic models   \n",
    "1. Neglecting heterogeneity and initial conditions\n",
    "   - does pooled OLS and probit consistently estimate APE of lagged y (state dependence)?\n",
    "   - what about other parameters?\n",
    "1. Accounting for heterogeneity and initial conditions \n",
    "    - is LPM-FE valid for dynamic models?\n",
    "    - can RE probit estimate APE of lagged y (state dependence)?\n",
    "    - what if x is correlated with c_i?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Specification: Pooled OLS Panel Regression\n",
      "Dep. var. : y \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "z               0.1905      0.0017    110.2546\n",
      "l1.y            0.1943      0.0041     47.4804\n",
      "const           0.5020      0.0036    139.3366\n",
      "y0              0.0003      0.0039      0.0791\n",
      "# of groups:       5000\n",
      "# of observations: 50000 \n",
      "\n",
      "Pooled probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               0.60269     0.00702    85.89036    -0.00000     0.19042\n",
      "l1.y            0.59363     0.01271    46.68870    -0.00000     0.18756\n",
      "const           0.00596     0.01071     0.55622    -0.00000     0.00188\n",
      "y0              0.00198     0.01228     0.16164    -0.00000     0.00063\n",
      "\n",
      "# of groups:      : 5000\n",
      "# of observations : 50000\n",
      "# log-likelihood. : -27847.01641782014 \n",
      "\n",
      "Iteration info: 6 iterations, 7 evaluations of objective, and 7 evaluations of gradients\n",
      "Elapsed time: 1.0743 seconds\n",
      "\n",
      "\n",
      "Specification: Linear Fixed Effects Regression\n",
      "Dep. var. : y \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "z               0.1887      0.0018    102.1330\n",
      "l1.y            0.0956      0.0042     22.5406\n",
      "# of groups:       5000\n",
      "# of observations: 50000 \n",
      "\n",
      "Random effects probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               0.60269     0.00701    86.03441    -0.00000     0.19042\n",
      "l1.y            0.59363     0.01355    43.79461    -0.00001     0.18756\n",
      "const           0.00597     0.01151     0.51890    -0.00001     0.00189\n",
      "y0              0.00196     0.01254     0.15601    -0.00004     0.00062\n",
      "sigma_a         0.00013    17.69664     0.00001     0.00001     0.00004\n",
      "\n",
      "# of groups:      : 5000\n",
      "# of observations : 50000\n",
      "# log-likelihood. : -27847.016425906735 \n",
      "\n",
      "Iteration info: 20 iterations, 20 evaluations of objective, and 14 evaluations of gradients\n",
      "Elapsed time: 11.2291 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sim=simulate(n=5000, nT=10, model='logit', delta=1, rho=1, sigma_a=0, phi_y0=0)\n",
    "xit=['z', 'l1.y']; xi=['const', 'y0']\n",
    "lpm_ols=lpd.estim(df_sim, 'y', xvar=xit + xi, groupvar='group', method='pols', cov_type='robust')\n",
    "res_pp=pooled(df_sim, 'y', xvar =xit + xi, groupvar='group', model='probit')\n",
    "lpm_fe=lpd.estim(df_sim, 'y',  xvar=xit, groupvar='group', method='fe', cov_type='robust')\n",
    "res_rep=rand_effect(df_sim, 'y', xvar =xit + xi , groupvar='group',model='probit', cov_type='sandwich', deriv=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some remarks on experiments - dynamic models   \n",
    "1. Pooled OLS and probit \n",
    "    - heavily over estimates APE on $y_{it-1}$ when $c_i$ is present (spurious state dependence)\n",
    "    - but provides good approximation on APE of $z_it$\n",
    "2. LMP-FE is not appropriate for dynamic models\n",
    "    - but still approximates APE of $z_it$ well when $c_i$ is uncorrelated with $y_0$\n",
    "    - underestimates state dependence when there is no unobserved heterogeneity\n",
    "    - we also see massive problems with spurious state dependence when $c_i$ and $y_0$ are correlated \n",
    "1. Accounting for heterogeneity and initial conditions \n",
    "    - RE probit estimates both parameters, partial effects and APEs  consistently, but is biased if $z_i$ is correlated with $c_i$. \n",
    "    - Solution within RE framework: allow for specified correlation between $c_i$ and $z_i$\n",
    "    - To allow for arbitrary correlation, we need to use dynamic fixed effects approach (Honoré and Kyriazidou, 2000), but we would the loose identification of APEs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Empirical Application: Married women's labor force participation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's first create some variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from indexmodels import *\n",
    "df = pd.read_stata('lfp.dta')\n",
    "Nobs=df['id'].count()\n",
    "df['const']=np.ones((Nobs,1))\n",
    "df[30:40]\n",
    "xbar_i=x_it.copy()\n",
    "i=0\n",
    "for j in x_it:\n",
    "    xbar_i[i]=j + '_bar'\n",
    "    df[j + '_bar']= df[j].groupby(df[groupvar]).transform('mean')\n",
    "    for t in range(5): \n",
    "        df[j + str(t+1)]=df[j].groupby(df[groupvar]).transform(lambda x: x.to_numpy()[t])\n",
    "        \n",
    "    i+=1\n",
    "df = addlag(df, 'lfp', t0=1)\n",
    "df['lfp1']=df['lfp'].groupby(df['id']).transform(lambda x: x.to_numpy()[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfp</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agesq</th>\n",
       "      <td>2209.000000</td>\n",
       "      <td>2209.000000</td>\n",
       "      <td>2209.000000</td>\n",
       "      <td>2209.000000</td>\n",
       "      <td>2209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kids</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hinc</th>\n",
       "      <td>4933.741211</td>\n",
       "      <td>5582.057129</td>\n",
       "      <td>5723.005371</td>\n",
       "      <td>6678.280762</td>\n",
       "      <td>8496.932617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lhinc</th>\n",
       "      <td>8.503853</td>\n",
       "      <td>8.627313</td>\n",
       "      <td>8.652249</td>\n",
       "      <td>8.806616</td>\n",
       "      <td>9.047461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kids_bar</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kids1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kids2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kids3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kids4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kids5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lhinc_bar</th>\n",
       "      <td>8.727498</td>\n",
       "      <td>8.727498</td>\n",
       "      <td>8.727498</td>\n",
       "      <td>8.727498</td>\n",
       "      <td>8.727498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lhinc1</th>\n",
       "      <td>8.503853</td>\n",
       "      <td>8.503853</td>\n",
       "      <td>8.503853</td>\n",
       "      <td>8.503853</td>\n",
       "      <td>8.503853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lhinc2</th>\n",
       "      <td>8.627313</td>\n",
       "      <td>8.627313</td>\n",
       "      <td>8.627313</td>\n",
       "      <td>8.627313</td>\n",
       "      <td>8.627313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lhinc3</th>\n",
       "      <td>8.652249</td>\n",
       "      <td>8.652249</td>\n",
       "      <td>8.652249</td>\n",
       "      <td>8.652249</td>\n",
       "      <td>8.652249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lhinc4</th>\n",
       "      <td>8.806616</td>\n",
       "      <td>8.806616</td>\n",
       "      <td>8.806616</td>\n",
       "      <td>8.806616</td>\n",
       "      <td>8.806616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lhinc5</th>\n",
       "      <td>9.047461</td>\n",
       "      <td>9.047461</td>\n",
       "      <td>9.047461</td>\n",
       "      <td>9.047461</td>\n",
       "      <td>9.047461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1.lfp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfp1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1            2            3            4\n",
       "id            1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "period        1.000000     2.000000     3.000000     4.000000     5.000000\n",
       "lfp           0.000000     1.000000     0.000000     0.000000     1.000000\n",
       "black         0.000000     0.000000     0.000000     0.000000     0.000000\n",
       "educ         12.000000    12.000000    12.000000    12.000000    12.000000\n",
       "age          47.000000    47.000000    47.000000    47.000000    47.000000\n",
       "agesq      2209.000000  2209.000000  2209.000000  2209.000000  2209.000000\n",
       "kids          1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "hinc       4933.741211  5582.057129  5723.005371  6678.280762  8496.932617\n",
       "per1          1.000000     0.000000     0.000000     0.000000     0.000000\n",
       "per2          0.000000     1.000000     0.000000     0.000000     0.000000\n",
       "per3          0.000000     0.000000     1.000000     0.000000     0.000000\n",
       "per4          0.000000     0.000000     0.000000     1.000000     0.000000\n",
       "per5          0.000000     0.000000     0.000000     0.000000     1.000000\n",
       "lhinc         8.503853     8.627313     8.652249     8.806616     9.047461\n",
       "const         1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "kids_bar      1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "kids1         1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "kids2         1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "kids3         1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "kids4         1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "kids5         1.000000     1.000000     1.000000     1.000000     1.000000\n",
       "lhinc_bar     8.727498     8.727498     8.727498     8.727498     8.727498\n",
       "lhinc1        8.503853     8.503853     8.503853     8.503853     8.503853\n",
       "lhinc2        8.627313     8.627313     8.627313     8.627313     8.627313\n",
       "lhinc3        8.652249     8.652249     8.652249     8.652249     8.652249\n",
       "lhinc4        8.806616     8.806616     8.806616     8.806616     8.806616\n",
       "lhinc5        9.047461     9.047461     9.047461     9.047461     9.047461\n",
       "l1.lfp             NaN     0.000000     1.000000     0.000000     0.000000\n",
       "lfp1          0.000000     0.000000     0.000000     0.000000     0.000000"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimation of static models \n",
    "(Col 1-4 Table 15.3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Specification: Linear Fixed Effects Regression\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "kids           -0.0389      0.0092     -4.2435\n",
      "lhinc          -0.0089      0.0046     -1.9469\n",
      "per2           -0.0043      0.0034     -1.2586\n",
      "per3           -0.0109      0.0042     -2.6034\n",
      "per4           -0.0123      0.0045     -2.7389\n",
      "per5           -0.0177      0.0049     -3.6429\n",
      "# of groups:       5663\n",
      "# of observations: 28315 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear FE - Column 1 of Table 15.3 \n",
    "lpm_fe=lpd.estim(df, y_it, xvar=x_it+x_t , groupvar='id', method='fe', cov_type='robust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled probit\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "kids           -0.19891     0.01562   -12.73582     0.00000    -0.06602\n",
      "lhinc          -0.21107     0.02525    -8.35840     0.00000    -0.07005\n",
      "educ            0.07969     0.00662    12.04501    -0.00000     0.02645\n",
      "black           0.22094     0.06615     3.33985     0.00000     0.07333\n",
      "age             0.14491     0.01225    11.82677    -0.00000     0.04810\n",
      "agesq          -0.00199     0.00015   -13.01384     0.00000    -0.00066\n",
      "per2           -0.01242     0.01046    -1.18792     0.00000    -0.00412\n",
      "per3           -0.03252     0.01274    -2.55182     0.00000    -0.01079\n",
      "per4           -0.04610     0.01364    -3.38036     0.00000    -0.01530\n",
      "per5           -0.05778     0.01464    -3.94689     0.00000    -0.01918\n",
      "const          -1.06443     0.26312    -4.04534     0.00000    -0.35328\n",
      "\n",
      "# of groups:      : 5663\n",
      "# of observations : 28315\n",
      "# log-likelihood. : -16556.671043420763 \n",
      "\n",
      "Iteration info: 20 iterations, 21 evaluations of objective, and 21 evaluations of gradients\n",
      "Elapsed time: 3.6373 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pooled probit - Column 2 of Table 15.3 \n",
    "res_pp=pooled(df, y_it, xvar=x_it + x_i + x_t + ['const'] , groupvar='id', model='probit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled probit\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "kids           -0.11736     0.02764    -4.24547     0.00000    -0.03885\n",
      "lhinc          -0.02881     0.01480    -1.94667     0.00000    -0.00954\n",
      "kids_bar       -0.08570     0.03192    -2.68449    -0.00000    -0.02837\n",
      "lhinc_bar      -0.25018     0.03615    -6.92019     0.00000    -0.08281\n",
      "educ            0.08413     0.00679    12.38859     0.00000     0.02785\n",
      "black           0.20307     0.06665     3.04686     0.00000     0.06722\n",
      "age             0.15164     0.01254    12.09028     0.00001     0.05019\n",
      "agesq          -0.00207     0.00016   -13.21160    -0.00000    -0.00068\n",
      "per2           -0.01357     0.01037    -1.30846    -0.00000    -0.00449\n",
      "per3           -0.03320     0.01272    -2.61072    -0.00000    -0.01099\n",
      "per4           -0.03903     0.01364    -2.86159     0.00000    -0.01292\n",
      "per5           -0.05524     0.01463    -3.77515     0.00000    -0.01829\n",
      "const          -0.72596     0.28525    -2.54497     0.00000    -0.24030\n",
      "\n",
      "# of groups:      : 5663\n",
      "# of observations : 28315\n",
      "# log-likelihood. : -16516.436454378927 \n",
      "\n",
      "Iteration info: 18 iterations, 19 evaluations of objective, and 19 evaluations of gradients\n",
      "Elapsed time: 3.4598 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pooled probit with xbar_i - Column 3 of Table 15.3 \n",
    "res_pp_CRE=pooled(df, y_it, xvar=x_it + xbar_i + x_i + x_t + ['const'] , groupvar='id', model='probit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random effects probit\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "kids           -0.39545     0.06131    -6.45043    -0.00000    -0.03156\n",
      "lhinc          -0.09946     0.04172    -2.38396    -0.00000    -0.00794\n",
      "kids_bar       -0.43154     0.08692    -4.96465    -0.00000    -0.03444\n",
      "lhinc_bar      -1.05936     0.12807    -8.27147    -0.00000    -0.08453\n",
      "educ            0.35047     0.02519    13.91497    -0.00000     0.02797\n",
      "black           0.81020     0.24304     3.33364    -0.00000     0.06465\n",
      "age             0.63511     0.04944    12.84737    -0.00000     0.05068\n",
      "agesq          -0.00862     0.00061   -14.04577    -0.00000    -0.00069\n",
      "per2           -0.04522     0.04500    -1.00488     0.00000    -0.00361\n",
      "per3           -0.12454     0.04496    -2.76984    -0.00000    -0.00994\n",
      "per4           -0.13537     0.04553    -2.97317     0.00000    -0.01080\n",
      "per5           -0.19964     0.04497    -4.43943     0.00000    -0.01593\n",
      "const          -3.23262     1.12904    -2.86315    -0.00000    -0.25795\n",
      "sigma_a         4.04129     0.10892    37.10376     0.00000     0.32248\n",
      "\n",
      "# of groups:      : 5663\n",
      "# of observations : 28315\n",
      "# log-likelihood. : -8634.94163136379 \n",
      "\n",
      "Iteration info: 87 iterations, 93 evaluations of objective, and 93 evaluations of gradients\n",
      "Elapsed time: 59.3248 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Correlated RE probit with xbar_i - Column 4 of Table 15.3 \n",
    "# NOTE: Looks like Wooldrige have used buggy version of STATA, sigma_a is heavly under estimated. \n",
    "#      New version of STATA gives results more siliar to what we find below\n",
    "sigma_a0=1\n",
    "theta0=res_pp_CRE.theta_hat*np.sqrt(1+sigma_a0**2)\n",
    "theta0=np.append(theta0,sigma_a0).reshape(-1,1)\n",
    "xvar=x_it + xbar_i + x_i + x_t + ['const']\n",
    "from indexmodels import *\n",
    "res_rep=rand_effect(df, y_it,xvar, groupvar='id', theta0=theta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimation of dynamic models \n",
    "(Selected results from Example 15.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled probit\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "l1.lfp          2.87568     0.03305    87.01890    -0.00000     0.35783\n",
      "kids           -0.06081     0.01084    -5.60930    -0.00002    -0.00757\n",
      "lhinc          -0.11429     0.02066    -5.53111    -0.00002    -0.01422\n",
      "educ            0.02920     0.00465     6.27961     0.00004     0.00363\n",
      "black           0.07940     0.04982     1.59365     0.00001     0.00988\n",
      "age             0.08445     0.00919     9.18934    -0.00000     0.01051\n",
      "agesq          -0.00110     0.00011    -9.80960     0.00006    -0.00014\n",
      "per3           -0.03400     0.04101    -0.82899     0.00001    -0.00423\n",
      "per4            0.00234     0.03776     0.06186     0.00000     0.00029\n",
      "per5           -0.03037     0.03474    -0.87429    -0.00000    -0.00378\n",
      "const          -2.17208     0.20884   -10.40090    -0.00001    -0.27028\n",
      "\n",
      "# of groups:      : 5663\n",
      "# of observations : 22652\n",
      "# log-likelihood. : -5332.528941573042 \n",
      "\n",
      "Iteration info: 29 iterations, 30 evaluations of objective, and 30 evaluations of gradients\n",
      "Elapsed time: 4.9374 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pooled probit with controls for correlation with x_it - spurious state dependence\n",
    "res_dyn_pp=pooled(df.dropna(), y_it, xvar=['l1.lfp'] + x_it + x_i +x_t[1:] + ['const'], groupvar='id', model='probit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled probit\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "l1.lfp          2.28905     0.04188    54.65101    -0.00000     0.27311\n",
      "kids            0.00059     0.07090     0.00834    -0.00000     0.00007\n",
      "lhinc          -0.05909     0.04758    -1.24175    -0.00000    -0.00705\n",
      "educ            0.02682     0.00568     4.72314    -0.00000     0.00320\n",
      "black           0.07372     0.06008     1.22698    -0.00000     0.00880\n",
      "age             0.07510     0.01151     6.52709    -0.00000     0.00896\n",
      "agesq          -0.00099     0.00014    -7.09032    -0.00001    -0.00012\n",
      "per3           -0.05126     0.04219    -1.21492    -0.00000    -0.00612\n",
      "per4           -0.02323     0.03858    -0.60224    -0.00000    -0.00277\n",
      "per5           -0.05500     0.03602    -1.52702    -0.00000    -0.00656\n",
      "const          -2.05821     0.26236    -7.84489     0.00000    -0.24557\n",
      "kids2           0.16390     0.07530     2.17662    -0.00000     0.01956\n",
      "kids3           0.03568     0.08100     0.44048    -0.00000     0.00426\n",
      "kids4           0.00511     0.08036     0.06355    -0.00000     0.00061\n",
      "kids5          -0.25342     0.06346    -3.99313    -0.00000    -0.03024\n",
      "lhinc2         -0.00492     0.03491    -0.14097    -0.00000    -0.00059\n",
      "lhinc3         -0.03693     0.03755    -0.98328    -0.00000    -0.00441\n",
      "lhinc4         -0.05213     0.03844    -1.35631    -0.00000    -0.00622\n",
      "lhinc5          0.03276     0.03567     0.91846    -0.00000     0.00391\n",
      "lfp1            0.81292     0.04126    19.70192    -0.00000     0.09699\n",
      "\n",
      "# of groups:      : 5663\n",
      "# of observations : 22652\n",
      "# log-likelihood. : -5109.341532805216 \n",
      "\n",
      "Iteration info: 32 iterations, 33 evaluations of objective, and 33 evaluations of gradients\n",
      "Elapsed time: 5.8923 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pooled probit with controls for correlation with x_it\n",
    "z_i=['kids2', 'kids3', 'kids4', 'kids5', 'lhinc2', 'lhinc3', 'lhinc4', 'lhinc5', 'lfp1']\n",
    "res_dyn_pp_controls=pooled(df.dropna(), y_it, xvar=['l1.lfp'] + x_it + x_i +x_t[1:] + ['const']+ z_i , groupvar='id', model='probit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random effects probit\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "l1.lfp          1.54208     0.06478    23.80336     0.00000     0.15540\n",
      "kids           -0.14553     0.07135    -2.03978     0.00000    -0.01467\n",
      "lhinc          -0.07483     0.04554    -1.64315     0.00000    -0.00754\n",
      "educ            0.04989     0.00879     5.67844     0.00000     0.00503\n",
      "black           0.13272     0.09027     1.47035     0.00000     0.01338\n",
      "age             0.12799     0.01797     7.12071     0.00000     0.01290\n",
      "agesq          -0.00169     0.00022    -7.58767     0.00000    -0.00017\n",
      "per3           -0.05556     0.03964    -1.40156     0.00000    -0.00560\n",
      "per4           -0.02920     0.04018    -0.72661     0.00000    -0.00294\n",
      "per5           -0.07834     0.04039    -1.93976     0.00000    -0.00789\n",
      "const          -2.94350     0.39756    -7.40398     0.00000    -0.29663\n",
      "kids2           0.32498     0.08675     3.74604     0.00000     0.03275\n",
      "kids3           0.10717     0.11264     0.95142     0.00000     0.01080\n",
      "kids4           0.01598     0.11483     0.13913     0.00000     0.00161\n",
      "kids5          -0.39057     0.09556    -4.08722     0.00000    -0.03936\n",
      "lhinc2         -0.02318     0.05302    -0.43723     0.00000    -0.00234\n",
      "lhinc3         -0.08317     0.05690    -1.46184     0.00000    -0.00838\n",
      "lhinc4         -0.08651     0.05804    -1.49055     0.00000    -0.00872\n",
      "lhinc5          0.06227     0.05365     1.16056     0.00000     0.00628\n",
      "lfp1            2.52744     0.13898    18.18547     0.00000     0.25470\n",
      "sigma_a         1.04910     0.05858    17.90921    -0.00000     0.10572\n",
      "\n",
      "# of groups:      : 5663\n",
      "# of observations : 22652\n",
      "# log-likelihood. : -5028.793068162922 \n",
      "\n",
      "Iteration info: 99 iterations, 108 evaluations of objective, and 108 evaluations of gradients\n",
      "Elapsed time: 86.3299 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random effects probit with controls for correlation with x_it\n",
    "sigma_a0=1\n",
    "theta0=res_dyn_pp_controls.theta_hat*np.sqrt(1+sigma_a0**2)\n",
    "theta0=np.append(theta0,sigma_a0).reshape(-1,1)\n",
    "res_dynrep=rand_effect(df.dropna(), y_it, xvar=['l1.lfp'] +x_it + x_i +x_t[1:] + ['const']+ z_i  , groupvar='id', model='probit', theta0=theta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State dependence estimated by dynamic random effects probit: 0.2594661053284748\n",
      "State dependence estimated by dynamic pooled probit: 0.8373020998208422\n"
     ]
    }
   ],
   "source": [
    "# Compute APE of lagged dependent variable in Dynamic Random effects probit\n",
    "Nobs, k, n, T, y, x = panel_setup(df.dropna(), y_it,  \n",
    "   xvar=['l1.lfp'] +x_it + x_i +x_t[1:] + ['const']+ z_i , groupvar='id')\n",
    "sigma_a_hat=res_dynrep.theta_hat[-1];\n",
    "beta_hat_a=res_dynrep.theta_hat[0:-1]/np.sqrt(1+sigma_a_hat**2)\n",
    "\n",
    "rho_hat=beta_hat_a[0,0]; \n",
    "beta_hat_a0=beta_hat_a.copy()\n",
    "beta_hat_a0[0,0]=0;\n",
    "Px0=G(x@beta_hat_a0, 'probit')\n",
    "Px1=G(x@beta_hat_a0 + rho_hat, 'probit')\n",
    "PE_lagy_RE=Px1-Px0 \n",
    "print('State dependence estimated by dynamic random effects probit:',np.mean(PE_lagy_RE))\n",
    "\n",
    "# Compute APE of lagged dependent variable in Dynamic Pooled probit\n",
    "Nobs, k, n, T, y, x = panel_setup(df.dropna(), y_it,  \n",
    "                                  xvar=['l1.lfp'] + x_it + x_i +x_t[1:] + ['const'] , groupvar='id')\n",
    "beta_hat_a=res_dyn_pp.theta_hat\n",
    "rho_hat=beta_hat_a[0,0]; \n",
    "beta_hat_a0=beta_hat_a.copy()\n",
    "beta_hat_a0[0,0]=0;\n",
    "Px0=G(x@beta_hat_a0, 'probit')\n",
    "Px1=G(x@beta_hat_a0 + rho_hat, 'probit')\n",
    "PE_lagy_Pooled=Px1-Px0 \n",
    "print('State dependence estimated by dynamic pooled probit:',np.mean(PE_lagy_Pooled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some remarks empirical example\n",
    "1. LPM-FE gives good approximation of APE for Kids and log(hinc) in static models\n",
    "2. Pooled Probit gives much higher estimates, indicating that Kids and log(hinc) are correlated with $c_i$\n",
    "3. RE-probit with controls for means of Kids and log(hinc) give results similar to LPM-FE\n",
    "3. In the dynamic model, pooled probit results in spurious state dependence (0.837) which is much higher than the results from the dynamic correlated random effects model (0.259)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "date": 1602643870.398518,
  "filename": "38_optimization.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "title": "Foundations of Computational Economics #38"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
