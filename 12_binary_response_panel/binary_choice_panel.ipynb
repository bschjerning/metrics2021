{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Binary reponse models for panel data\n",
    "\n",
    "### Econometrics B (ØkB)\n",
    "\n",
    "Wooldridge (2010, Section 15.8)\n",
    "\n",
    "Bertel Schjerning\n",
    "\n",
    "Department of Economics, University of Copenhagen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plan for panel data models for binary response\n",
    "1. Binary response models without unobserved effects\n",
    "2. Unobserved effects models under strict exogeneity\n",
    "3. Dynamic unobserved effects models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Panel data\n",
    "\n",
    "$T$ observations of $N$ individuals\n",
    "$$\n",
    "y_{it},x_{it}\\text{,  }i=1,...,N\\text{, }t=1,..,T\n",
    "$$\n",
    "where $y_{it}=\\left \\{ 0,1\\right \\} $ is a binary random variable\n",
    "\n",
    "As usual, we assume random sampling over $i$ (but not over $t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Panel data: Married women's labor force participation\n",
    "- Main empirical example thoughout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>lfp</th>\n",
       "      <th>black</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>agesq</th>\n",
       "      <th>kids</th>\n",
       "      <th>hinc</th>\n",
       "      <th>per1</th>\n",
       "      <th>per2</th>\n",
       "      <th>per3</th>\n",
       "      <th>per4</th>\n",
       "      <th>per5</th>\n",
       "      <th>lhinc</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>1369</td>\n",
       "      <td>2</td>\n",
       "      <td>2308.281006</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.744258</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>1369</td>\n",
       "      <td>2</td>\n",
       "      <td>2529.024414</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.835589</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>1369</td>\n",
       "      <td>2</td>\n",
       "      <td>2462.321289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.808860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>1369</td>\n",
       "      <td>2</td>\n",
       "      <td>2427.562500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.794643</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>1369</td>\n",
       "      <td>2</td>\n",
       "      <td>2409.660156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.787241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>3603.627686</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.189696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>1509.604492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.319603</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>1489.667603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.306308</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>1413.338989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.253710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>1215.146729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.102620</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  period  lfp  black  educ  age  agesq  kids         hinc  per1  per2  \\\n",
       "30   7       1    1      1    12   37   1369     2  2308.281006     1     0   \n",
       "31   7       2    1      1    12   37   1369     2  2529.024414     0     1   \n",
       "32   7       3    1      1    12   37   1369     2  2462.321289     0     0   \n",
       "33   7       4    1      1    12   37   1369     2  2427.562500     0     0   \n",
       "34   7       5    1      1    12   37   1369     2  2409.660156     0     0   \n",
       "35   8       1    1      0    18   29    841     1  3603.627686     1     0   \n",
       "36   8       2    1      0    18   29    841     1  1509.604492     0     1   \n",
       "37   8       3    1      0    18   29    841     1  1489.667603     0     0   \n",
       "38   8       4    1      0    18   29    841     1  1413.338989     0     0   \n",
       "39   8       5    1      0    18   29    841     1  1215.146729     0     0   \n",
       "\n",
       "    per3  per4  per5     lhinc  const  \n",
       "30     0     0     0  7.744258    1.0  \n",
       "31     0     0     0  7.835589    1.0  \n",
       "32     1     0     0  7.808860    1.0  \n",
       "33     0     1     0  7.794643    1.0  \n",
       "34     0     0     1  7.787241    1.0  \n",
       "35     0     0     0  8.189696    1.0  \n",
       "36     0     0     0  7.319603    1.0  \n",
       "37     1     0     0  7.306308    1.0  \n",
       "38     0     1     0  7.253710    1.0  \n",
       "39     0     0     1  7.102620    1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_stata('lfp.dta')\n",
    "Nobs=df['id'].count()\n",
    "df['const']=np.ones((Nobs,1))\n",
    "df[30:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some more Python Libraries and variables used in various specifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as la\n",
    "from tabulate import tabulate\n",
    "import linearpaneldata as lpd   # simple routines to do linear FE and Pooled OLS regressions\n",
    "from indexmodels import *       # objective functions etc. for estimation of panel data binary response models\n",
    "import mestim as M              # routines for M-estimation given general sample objective functions\n",
    "\n",
    "# names of variables use thoughout\n",
    "y_it=['lfp']                           # binary response variable: Labor force participation\n",
    "x_it=['kids', 'lhinc']                 # time varying explanatory varibles  \n",
    "x_t=['per2', 'per3', 'per4', 'per5']   # time dummies (leave one out)\n",
    "x_i=['educ','black', 'age', 'agesq']   # time constant explanatory varibles (not used in FE regressions)\n",
    "groupvar = 'id'                        # individual indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Object of interest\n",
    "We are interested in modeling\n",
    "$$\n",
    "P\\left(y_{it}=1|x_{it},c_{i}\\right) \n",
    "$$\n",
    "\n",
    "That is, the response probability - holding $x_{it}$ and $c_i$ constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A starting point: Linear Probability Model\n",
    "Linear unobserved effects model:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "P\\left( y_{it}=1|x_{it},c_{i}\\right) &=&E\\left[ y_{it}=1|x_{it},c_{i}\\right] \\\\\n",
    "&=&x_{it}\\beta +c_{i}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Problems are the usual ones:\n",
    "- $P\\left( y_{it}=1|x_{it},c_{i}\\right)$ not bounded between zero and one\n",
    "- $V\\left( y_{it}|x_{it},c_{i}\\right) $ depend on $x$ and $c_{i}$ (Heteroscedasticity)\n",
    "- ***and*** unnatural restrictions on $c_{i}$, $-x_{it}\\beta \\leq c_{i}\\leq 1-x_{it}\\beta $\n",
    "\n",
    "Advantages\n",
    "- Easy to remove $c_{i}$ (within transformation, FD, etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameter Estimates - Linear Fixed Effects Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Specification: Linear Fixed Effects Regression\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "kids           -0.0389      0.0092     -4.2435\n",
      "lhinc          -0.0089      0.0046     -1.9469\n",
      "per2           -0.0043      0.0034     -1.2586\n",
      "per3           -0.0109      0.0042     -2.6034\n",
      "per4           -0.0123      0.0045     -2.7389\n",
      "per5           -0.0177      0.0049     -3.6429\n",
      "# of groups:       5663\n",
      "# of observations: 28315 \n",
      "\n",
      "\n",
      "Specification: Pooled OLS Panel Regression\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "kids           -0.0679      0.0050    -13.5242\n",
      "lhinc          -0.0645      0.0067     -9.6000\n",
      "per2           -0.0024      0.0037     -0.6350\n",
      "per3           -0.0091      0.0045     -2.0335\n",
      "per4           -0.0130      0.0047     -2.7487\n",
      "per5           -0.0169      0.0051     -3.3310\n",
      "educ            0.0267      0.0021     12.6252\n",
      "black           0.0718      0.0199      3.6047\n",
      "age             0.0544      0.0029     18.9785\n",
      "agesq          -0.0007      0.0000    -20.0756\n",
      "# of groups:       5663\n",
      "# of observations: 28315 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column 1 in table 15.3 Wooldridge (p. 623)\n",
    "lpm_fe=lpd.estim(df, y_it, xvar=x_it+x_t , groupvar='id', method='fe', cov_type='robust')\n",
    "lpm_pols=lpd.estim(df, y_it, xvar=x_it+x_t+x_i, groupvar='id', method='pols', cov_type='robust')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Index models without unobserved effects\n",
    "Assume no unobserved effect\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{it}\\right) =G\\left( x_{it}\\beta \\right) ,t=1,2,...,T%\n",
    "$$\n",
    "\n",
    "We have not nearly assumed enough to obtain joint distribution of $\n",
    "y_{i}=\\{y_{i1},..,y_{iT}\\}$ given $x_{i}=\\{x_{i1},..,x_{iT}\\}$\n",
    "\n",
    "- Example:$\\ y_{i}|x_{i}$ could be serially correlated\n",
    "- **We need more assumptions to use CMLE!**\n",
    "\n",
    "Could we use another estimator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimator: Partial MLE\n",
    "\n",
    "Readings: Partial MLE (Wooldridge 13.8)\n",
    "\n",
    "We can obtain a $\\sqrt{N}$ consistent estimator of $\\beta $ by maximizing *partial* likelihood\n",
    "\n",
    "$$\n",
    "\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{t=1}^{T}\\left \\{ \\underset{\\ell _{it}\\left(\n",
    "y_{i}|x_{i};\\beta \\right) }{\\underbrace{y_{it}\\ln \\left( G\\left( x_{it}\\beta\n",
    "\\right) \\right) +\\left( 1-y_{it}\\right) \\ln \\left( 1-G\\left( x_{it}\\beta\n",
    "\\right) \\right) }}\\right \\} \n",
    "$$\n",
    "\n",
    "Note that $\\hat{\\beta}_{PML}$ *is clearly an M-estimator*\n",
    "\\begin{eqnarray*}\n",
    "\\hat{\\beta}_{PML} &=&\\arg \\min_{\\beta \\in \\Theta }\\frac{1}{N}\n",
    "\\sum_{i=1}^{N}q\\left( y_{i}|x_{i};\\beta \\right) \\text{, where} \\\\\n",
    "q\\left( y_{i}|x_{i};\\beta \\right) &=&-\\sum_{t=1}^{T}\\ell _{it}\\left(\n",
    "y_{i}|x_{i};\\beta \\right) \n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def Q_pooled(y, x, T, beta, model='probit', out='Q'):\n",
    "    ''' Pooled linear index model for panel data. e.g pooled probit or logit\n",
    "        y:      Nobs x 1 np.array of binary response data\n",
    "        x:      Nobs x k np.array of explanatory variables\n",
    "        T:      n x 1  np.array of containing number of time observations for each group \n",
    "        model:  'probit' or 'logit'\n",
    "        out:    controls what is returned - can be 'predict','Q', 'dQ', 's_i', or 'H'\n",
    "    '''\n",
    "\n",
    "    beta=np.array(beta).reshape(-1,1)             # parameters\n",
    "    n=T.shape[0];                                 # number of groups\n",
    "    xb=x @ beta                                   # Linear index \n",
    "    Gx=G(xb, model)                               # Response probability at x\n",
    "    gx=g(xb, model)                               # Density at xb\n",
    "    Gx=np.minimum(np.maximum(Gx,1e-15),1-1e-15)   # Truncating Gx\n",
    "    if out=='predict':  return xb, Gx, gx         # Return predicted values\n",
    "\n",
    "    ll_it = np.log(Gx)*y + np.log(1-Gx)*(1-y)     # Nobsx1 vector of log-likelihood contributions for group i at time t\n",
    "    q_i= - sumby(ll_it, T)                        # nx1 vector of (negative) log-likelihood contributions \n",
    "    if out=='Q': return np.mean(q_i);             # Return Q: sample objective function to be minimized - negative of log-likelihood\n",
    "\n",
    "    # 1st order derivatives\n",
    "    s_it=gx*x*(y-Gx)/( Gx* (1-Gx))                # NobsxK array of derivatives of ll_it\n",
    "    s_i = sumby(s_it, T)                          # nxK array of derivatives of ll_i (transposed scores staked over i)\n",
    "    if out=='s_i': return s_i                     # Return s_i: nxK array with scores\n",
    "    if out=='dQ':  return -np.mean(s_i, axis=0);  # Return dQ: array of size K derivative of sample objective function\n",
    "\n",
    "    # 2nd order derivatives\n",
    "    H=(gx*x).T @(gx*x/(Gx* (1-Gx)))/n             # Analytical Hessian averaged over all groups i\n",
    "    # H=s_it.T@ s_it/n                            # Alternative: use product of gradient as Hessian approximation\n",
    "    if out=='H':    return H; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameter Estimates - Pooled Probit\n",
    "Column 2 in table 15.3 Wooldridge (p. 623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled probit\n",
      "Dep. var. : ['lfp'] \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "kids           -0.19891     0.01445   -13.76457    -0.00000    -0.06602\n",
      "lhinc          -0.21107     0.02159    -9.77522     0.00000    -0.07005\n",
      "per2           -0.01242     0.01034    -1.20178     0.00000    -0.00412\n",
      "per3           -0.03252     0.01168    -2.78368    -0.00000    -0.01079\n",
      "per4           -0.04610     0.01257    -3.66801    -0.00000    -0.01530\n",
      "per5           -0.05778     0.01242    -4.65278     0.00000    -0.01918\n",
      "educ            0.07969     0.00618    12.88540    -0.00000     0.02645\n",
      "black           0.22094     0.05933     3.72402    -0.00000     0.07333\n",
      "age             0.14492     0.01097    13.20588     0.00000     0.04810\n",
      "agesq          -0.00199     0.00014   -14.46445     0.00000    -0.00066\n",
      "const          -1.06445     0.22302    -4.77280    -0.00000    -0.35328\n",
      "\n",
      "# of groups:      : 5663\n",
      "# of observations : 28315\n",
      "# log-likelihood. : -16556.671043389644 \n",
      "\n",
      "Iteration info: 26 iterations, 33 evaluations of objective, and 33 evaluations of gradients\n",
      "Elapsed time: 3.0301 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pooled(df, yvar, xvar, groupvar, model='probit', cov_type='sandwich', deriv=1): \n",
    "    print('Pooled', model)\n",
    "    Nobs, k, n, T, y, x = panel_setup(df, yvar, xvar, groupvar)\n",
    "    Qfun     = lambda beta, out:  Q_pooled(y, x, T, beta, model, out)\n",
    "    res=M.estimation(Qfun, theta0=np.zeros((k,1)), deriv=deriv, cov_type=cov_type, parnames=xvar)\n",
    "    xb, Gx, gx = Qfun(res.theta_hat, out='predict')\n",
    "    APE=np.mean(gx)*res.theta_hat\n",
    "    res.update(dict(zip(['yvar', 'xvar', 'Nobs','k', 'n', 'T', 'APE'], [yvar, xvar, Nobs, k, n, T, APE])))\n",
    "    print_output(res)\n",
    "    return res\n",
    "res_pp=pooled(df, y_it, xvar=x_it+x_t+x_i + ['const'] , groupvar='id', model='probit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Properties of Partial MLE\n",
    "\n",
    "**Since $\\hat{\\beta}_{PML}$ is an M-estimator**\n",
    "- $\\hat{\\beta}_{PML}$ is consistent (if identified) - by theorem 12.2 \n",
    "- $\\hat{\\beta}_{PML}$ is asymptotic normal - by theorem 12.3\n",
    "\n",
    "\n",
    "**But objective function is not based a the conditional density of $y_{i}$ given $x_{i;}$**\n",
    "- Need to do inference using the methods of ch. 12 to take account for potential serial correlation\n",
    "- Variance-covariance matrix on the form, $A^{-1}BA^{-1}$, $A\\neq B$\n",
    "- Wald Statistics (12.63) and score statistics (12.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parnames      theta_hat        Ainv        Binv    sandwich\n",
      "----------  -----------  ----------  ----------  ----------\n",
      "kids           -0.19891     0.00725     0.00367     0.01445\n",
      "lhinc          -0.21107     0.01226     0.00702     0.02159\n",
      "per2           -0.01242     0.02390     0.06298     0.01034\n",
      "per3           -0.03252     0.02312     0.05302     0.01168\n",
      "per4           -0.04610     0.02311     0.05503     0.01257\n",
      "per5           -0.05778     0.02256     0.04868     0.01242\n",
      "educ            0.07969     0.00311     0.00157     0.00618\n",
      "black           0.22094     0.03163     0.01698     0.05933\n",
      "age             0.14492     0.00582     0.00312     0.01097\n",
      "agesq          -0.00199     0.00007     0.00004     0.00014\n",
      "const          -1.06445     0.12645     0.07970     0.22302\n"
     ]
    }
   ],
   "source": [
    "def avar(s_i, Ainv, cov_type ='sandwich'):\n",
    "    n, K=s_i.shape\n",
    "    B=s_i.T@ s_i/n \n",
    "    if cov_type=='Binv':        return la.inv(B)/n\n",
    "    if cov_type=='Ainv':        return Ainv/n;         \n",
    "    if cov_type=='sandwich':    return Ainv @ B @ Ainv/n\n",
    "\n",
    "se={'parnames':res_pp.xvar, 'theta_hat':res_pp.theta_hat}\n",
    "for cov_type in ['Ainv', 'Binv', 'sandwich']:\n",
    "    cov = avar(res_pp.s_i, res_pp.hess_inv, cov_type)\n",
    "    se[cov_type]=  np.sqrt(np.diag(cov))\n",
    "print(tabulate(se, headers=\"keys\",floatfmt=\"10.5f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What did we assume?\n",
    "\n",
    "1. No unobserved effects\n",
    "2. Linear Index structure \n",
    "\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{it}\\right) =G\\left( x_{it}\\beta \\right) \n",
    "$$\n",
    "\n",
    "3. A functional form for $G\\left( {}\\right)$. \n",
    "\t- For example: $G\\left( {}\\right) =\\Phi \\left( {}\\right) $ (Pooled Probit)\n",
    "\n",
    "- We will relax 1) later in this lecture\n",
    "\n",
    "- Semi/Non-parametric approaches can be used to relax 2) and 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What did we NOT assume?\n",
    "\n",
    "1. Dynamic Completeness\n",
    "\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{it},y_{it-1},x_{it-1},y_{it-2},....\\right) =P\\left(\n",
    "y_{it}=1|x_{it}\\right) \n",
    "$$\n",
    "\n",
    "2. Strict exogeneity (conditional on a unobserved effect)\n",
    "\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{i},c_{i}\\right) =P\\left( y_{it}=1|x_{it},c_{i}\\right) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Under dynamic completeness\n",
    "\n",
    "Dynamically complete models\n",
    "\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{it},y_{it-1},x_{it-1},y_{it-2},....\\right) =P\\left(\n",
    "y_{it}=1|x_{it}\\right) \n",
    "$$\n",
    "\n",
    "- We are not assuming independence ($x_{it}$ can contain lagged dependent variables)\n",
    "- Easier to justify when $x_{it}$ contains lagged values of $y_{it}$ and $x_{it}$\n",
    "- Does not imply independence: \n",
    "\t- $x_{it}$ can contain lagged dependent variables\n",
    "\t- But scores are independent across $t$\n",
    "- Inference is easier\n",
    "    - We can just treat the sample as one big cross-section of size $NT$\n",
    "\n",
    "    - Why: $A_{0}=B_{0}$ for PML when scores are serially uncorrelated (see 13.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Test for dynamic completeness\n",
    "\n",
    "1. Estimate artificial model and generate residuals \n",
    "$$\n",
    "\\hat{u}_{it}=y_{it}-G\\left( x_{it}\\hat{\\beta}\\right) \n",
    "$$\n",
    "\n",
    "2. Estimate model where residuals is included \n",
    "$$\n",
    "P\\left( y_{it}=1|x_{it},\\hat{u}_{it-1}\\right) =G\\left( x_{it}\\beta +\\gamma _{1}\\hat{u}_{it-1}\\right)\n",
    "$$\n",
    "\n",
    "3. Test $H_{0}:\\gamma _{1}=0$. \n",
    "\n",
    "If $H_{0}$ is rejected so is dynamic completeness.\n",
    "\n",
    "- This works because $u_{it}$ must uncorrelated with any function of \n",
    "$\\left\\{x_{it},y_{it-1},x_{it-1},y_{it-2}...\\right \\} $ including $u_{it-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unobserved Effects Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Unobserved Effects Models under Strict Exogeneity\n",
    "\n",
    "**Strict exogeneity (and index restriction) implies**\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "P\\left( y_{it}=1|x_{i},c_{i}\\right) &=&P\\left( y_{it}=1|x_{it},c_{i}\\right) \\\\\n",
    "&=&G\\left( x_{it}\\beta +c_{i}\\right) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "**Strict Exogeneity**\n",
    "- $x_{it}$ cannot include lagged dependent variables or explanatory variables with feedback from current and past values of $y_{it}$\n",
    "\n",
    "- Reason is completelely anologous to our previous discussion for the linear model\n",
    "\n",
    "**Problem: $c_{i}$ is unobserved**\n",
    "\n",
    "- We can not condition on $c_{i}$ (it is unobserved)\n",
    "- It cannot be differenced away - due to the nonlinearity of $G()$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to deal with unobserved effect?\n",
    "\n",
    "Some possibilities: \n",
    "\n",
    "1. **Estimate $c_{i}$** (treat as a parameter)\n",
    "\t- We can never consistently estimate $c_{i}$ for a given $T$\n",
    "\t- Incidental Parameters Problem}: $\\hat{\\beta}$ is not $\\sqrt{N}$-consistent for fixed $T$ (unlike in the linear case)\n",
    "\t- Need long panel to estimate $c_{i}$ (at least 7-10 observations for each individual)\n",
    "\n",
    "2. **Random Effects:** Assume distribution of $c_{i}|x_{i}$ and integrate out $c_{i}$.\n",
    "\t- How do we come up with a distribution \n",
    "\t- Example below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More possibilities\n",
    "\n",
    "3. **Fixed Effects:** Eliminate $c_{i}$ by transformation\n",
    "\t- We can not difference $c_{i}$ out - due to non-linearity\n",
    "\t- Not easy to find transformation (vary from model to model)\n",
    "\t- Example below\n",
    "\n",
    "4. **Pooled analysis**\n",
    "\t- if we are willing to assume particular random effects structure and interest is in $APE$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Effects: Assumptions\n",
    "\n",
    "Random Effects Linear Index Models\n",
    "1. Strict exogeneity (and index structure)\n",
    "$$\n",
    "P\\left( y_{it}=1|x_{i},c_{i}\\right) =G\\left( x_{it}\\beta +c_{i}\\right) \n",
    "$$\n",
    "2. Independence of $y_{i1},..,y_{iT}$ conditional on $\\left(x_{i},c_{i}\\right)$\n",
    "implies that : $f\\left( y_{1},..,y_{T}|x_{i},c;\\beta \\right)=\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c,\\beta \\right) $\n",
    "\n",
    "3. Normality of $c_{i}|x_{i}$\n",
    "$$\n",
    "c_{i}|x_{i}\\sim N\\left( 0,\\sigma _{c}^{2}\\right) \n",
    "$$\n",
    "Implies: $c_{i}$ and $x_{i}$ are independent and that $c_{i}$ has a normal distribution\n",
    "\n",
    "Alternative to 3): Discrete support for $c_{i}$ and independence between $x_{i}$ and $c_{i}$\n",
    "\n",
    "Under these assumptions we can estimate model with CMLE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Effects: Discrete support \n",
    "Joint distribution of $y_{i}|x_{i}$\n",
    "$$\n",
    "f\\left( y_{1},..,y_{T}|x_{i};\\theta \\right) =\\sum_{j}\\pi\n",
    "^{j}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c^{j},\\beta \\right) \n",
    "$$\n",
    "where \n",
    "$$\n",
    "f(y_{t}|x_{it},c,\\beta) =  y_{t}G(x_{it}\\beta +c) + (1-y_{t}) [ 1-G(x_{it}\\beta +c)]\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\sum_{j}\\pi ^{j}=1\\text{  and }\\sum_{j}\\pi ^{j}c^{j}=0\n",
    "$$\n",
    "\n",
    "NOTE: $\\pi ^{j}$ and $c^{j}$ are parameters to be estimated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Effects: Discrete Support\n",
    "**Examble with 2 support points: $c^{l}$ and $c^{h}$**\n",
    "Joint distribution of $y_{i}|x_{i}$\n",
    "\\begin{eqnarray*}\n",
    "f\\left( y_{1},..,y_{T}|x_{i};\\theta \\right) &=&\\pi^{l}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c^{l},\\beta \\right) \\\\\n",
    "&&+\\left( 1-\\pi ^{l}\\right) \\prod_{t=1}^{T}f\\left( y_{t}|x_{it},-\\pi^{l}/\\left( 1-\\pi ^{l}\\right) c^{l},\\beta \\right) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "Two additional parameters to be estimated\n",
    "- Probability of being a low type, $\\pi$\n",
    "- Support point for low type, $c^{l}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Effects: Normally Distributed $c_i$\n",
    "\n",
    "Joint distribution of $y_{i}|x_{i}$\n",
    "\n",
    "$$\n",
    "f\\left( y_{1},..,y_{T}|x_{i};\\theta \\right) =\\int_{-.\\infty }^{\\infty\n",
    "}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c,\\beta \\right) \\frac{1}{\\sigma _{c}}%\n",
    "\\phi \\left( c/\\sigma _{c}\\right) dc\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "f\\left( y_{t}|x_{it},c,\\beta \\right) = y_{t}G\\left( x_{it}\\beta +c\\right) +\n",
    "\\left( 1-y_{t}\\right) \\left[ 1-G\\left( x_{it}\\beta +c\\right) \\right]\n",
    "$$\n",
    "\n",
    "**How to evaluate integral?**\n",
    "\n",
    "1. Gaussian Quadrature\n",
    "(for example Gauss-Hermite quadrature for integrals on the form $\\int_{-.\\infty}^{\\infty }h\\left( z\\right) \\exp \\left( -z^{2}\\right) dz$)\n",
    "2. Simulation (The integrals equivalent to take expectations over random variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RECAP: Gaussian quadrature\n",
    "\n",
    "General formula\n",
    "\n",
    "$$\n",
    "\\int_a^b f(x)w(x) dx = \\sum_{i=1}^n \\omega_i f(x_i) + \\text{approximation error}\n",
    "$$\n",
    "\n",
    "- $w(x)$ non-negative weighting function\n",
    "- $ x_i \\in [a,b] $ quadrature nodes  \n",
    "- $ \\omega_i $ quadrature weights\n",
    "- Nodes and weights are chosen so that there is no approximation error if $f(x)$ belongs to the family of $2n-1$ degree polynomials\n",
    "- Choice of method differ by weighting function $w(x)$ and domain $[a, b]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussian quadrature\n",
    "$$\n",
    "\\int_a^b f(x)w(x) dx = \\sum_{i=1}^n \\omega_i f(x_i) + \\text{approximation error}\n",
    "$$\n",
    "\n",
    "- Gauss-Legendre Quadrature ($w(x)=1$, domain $[a, b]$)\n",
    "- Gauss-Chebyshev Quadrature ($w(x)=(1-x^2)^{(-1/2)} $, domain  $[a, b]$)\n",
    "- Gauss-Hermite Quadrature ($w(x)=\\exp(−𝑥^2)$, domain  $[-\\infty, \\infty]$)\n",
    "- Gauss-Laguerre Quadrature ($w(x)=\\exp(−𝑥)$, domain  $[a, \\infty]$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gauss-Legendre Quadrature\n",
    "\n",
    "- Domain $ [-1,1]$ .. or   $[a,b]$\n",
    "- Weighting $ 1 $  \n",
    "\n",
    "\n",
    "$$\n",
    "\\int_{-1}^1 f(x) dx = \\sum_{i=1}^{n} \\omega_i f(x_i) + \\frac{2^{2n+1}(n!)^4}{(2n+1)!(2n)!}\\frac{f^{(2n)}(\\xi)}{(2n)!}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Nodes and weights come from Legendre polynomials, values tabulated  \n",
    "- Good for computing expectation of random variables with finite support.\n",
    "- Can also be used for computing expectation if transforming using inverse CDF (has domain [0,1]]\n",
    "- The method of choice when no obvious weighting function can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Change of variable for Gauss-Legendre\n",
    "A linear change of variable is nessesary to apply Gauss-Legendre quadrature to general intervals $[a, b]$ rather than $[−1, 1]$ \n",
    "\n",
    "This change of interval from $[a, b]$ to $[−1, 1]$ can be done in the following way:\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\int _{a}^{b}f(x)\\,dx={\\frac {b-a}{2}}\\int _{-1}^{1}\n",
    "f\\left({\\frac {(x+1)(b-a)}{2} +a }\\right)\\,dx .}\n",
    "$$\n",
    "\n",
    "Applying n point Gaussian quadrature ${\\displaystyle (x ,w)}$ rule then results in the following approximation:\n",
    "\n",
    "$$\n",
    "{\\displaystyle \\int _{a}^{b}f(x)\\,dx\\approx {\\frac {b-a}{2}}\\sum _{i=1}^{n}w_{i}\n",
    "f\\left({\\frac {(x_i+1)(b-a)}{2} +a }\\right)\\,dx .}\n",
    "%f\\left({\\frac {b-a}{2}}x _{i}+{\\frac {a+b}{2}}\\right).}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approximation of joint distribution of $y_{i}|x_{i}$ using Gauss-Legendre\n",
    "We can reformulate the integral by making the simple change of variable \n",
    "$$c_i=\\sigma _{c}\\Phi^{-1}(q_i)$$ \n",
    "where $q_i$ is now uniformly rather than normally distributed\n",
    "\n",
    "We get\n",
    "\\begin{eqnarray*}\n",
    "f\\left( y_{1},..,y_{T}|x_{i};\\theta \\right) \n",
    "&=&\\int_{-.\\infty }^{\\infty}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c,\\beta \\right) \\frac{1}{\\sigma _{c}}\\phi \\left( c/\\sigma _{c}\\right) dc \\\\\n",
    "&=&\\int_{0}^{1}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},\\sigma _{c}\\Phi^{-1}(q),\\beta \\right) dq\n",
    "\\end{eqnarray*}\n",
    "This integral is easily approximated by Gauss-Legendre quadrature \n",
    "$$\n",
    "\\int_{0}^{1}\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},\\sigma _{c}\\Phi^{-1}(q),\\beta \\right) dq \\approx\n",
    "\\sum_{j=1}^{m}w_j\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},\\sigma _{c}\\Phi^{-1}(q_j),\\beta \\right)=\n",
    "\\sum_{j=1}^{m}w_j f(q_j)\n",
    "$$\n",
    "where $w_j$ and $q_j$ are Gauss-Legendre weights and nodes for adjusted to the interval $[0,1]$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def Q_RE(y, x, T, theta, model='probit', out='Q', R=20, rng=random.default_rng(seed=11)):\n",
    "    ''' Pooled linear index model for panel data. e.g pooled probit or logit\n",
    "        y:      Nobs x 1 np.array of binary response data\n",
    "        x:      Nobs x k np.array of explanatory variables\n",
    "        T:      n x 1  np.array of containing number of time observations for each group \n",
    "        model:  'probit' or 'logit'\n",
    "        out:    controls what is returned - can be 'predict','Q', 'dQ', 's_i', or 'H'\n",
    "    '''\n",
    "    Nobs, k= x.shape\n",
    "    n=T.shape[0];                                 # number of groups\n",
    "\n",
    "    sigma_a=theta[-1]                             # heterogeneity parameter\n",
    "    beta=np.array(theta[:-1]).reshape(-1,1)       # slope parameters\n",
    "    \n",
    "    xb=x @ beta                                   # Linear index \n",
    "    gx=g(xb, model)                               # Density at xb\n",
    "    Gx=G(xb).reshape(-1,1)\n",
    "    if out=='predict':  return xb, Gx, gx         # Return predicted values\n",
    "\n",
    "    # compute alpha for used sample objective function at Legendre quadrature nodes\n",
    "    q,w=quad_xw(R, a=0, b=1)\n",
    "    q=q.reshape(1,R)\n",
    "    w=w.reshape(1,R)\n",
    "    eta=norm.ppf(q);\n",
    "    alpha=sigma_a*eta\n",
    "\n",
    "    G_itq=G(xb + alpha, model)                          # Reponse probability at x for each quadrature point (Nobs x R)\n",
    "    G_itq=np.minimum(np.maximum(G_itq,1e-15),1-1e-15)   # Truncating G\n",
    "    F_itq = G_itq*y + (1-G_itq)*(1-y)                   # Nobsx1 vector of log-likelihood contributions for group i at time t\n",
    "    F_iq  = prodby(F_itq,T)                             # product over time, n by R\n",
    "    Fi = np.sum(F_iq*w, axis=1).reshape(-1,1)           # sum over quad/sims, n by 1 (likelihood contribution for unit i)\n",
    "    q_i= - np.log(Fi)                                   # nx1 vector of (negative) log-likelihood contributions \n",
    "    if out=='Q': return np.mean(q_i);                   # Return Q: sample objective function to be minimized - negative of log-likelihood\n",
    "\n",
    "    # 1st order derivatives\n",
    "    g_itq=g(xb + alpha, model)\n",
    "    s_itq=g_itq*(y-G_itq)/(G_itq*(1-G_itq)) # Nobs x R\n",
    "    n_p=theta.shape[0]\n",
    "    s_i=np.empty((n, n_p))                          # nxK+1 array of derivatives of ll_i (transposed scores staked over i)\n",
    "    for ip in range(n_p-1):\n",
    "        dw_iq=sumby(s_itq*x[:,ip].reshape(-1,1), T);  # n x R \n",
    "        s_i[:,ip]=np.sum(w*F_iq*dw_iq/Fi.reshape(-1,1),axis =1)  # sum over quad/sim points\n",
    "    dw_iq=sumby(s_itq*eta, T);  # n x R \n",
    "    s_i[:,-1]=np.sum(w*F_iq*dw_iq/Fi,axis =1)       \n",
    "    if out=='s_i': return s_i                       # Return s_i: nxK array with scores\n",
    "    if out=='dQ':  return -np.mean(s_i, axis=0);    # Return dQ: array of size K derivative of sample objective function\n",
    "\n",
    "    # 2nd order derivatives\n",
    "    H=s_i.T@ s_i/n                                  # Alternative: use product of gradient as Hessian approximation\n",
    "    if out=='H':    return H; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gauss-Hermite Quadrature\n",
    "\n",
    "- Domain $ [-\\infty,\\infty] $  \n",
    "- Weighting $ \\exp(-x^2) $  \n",
    "\n",
    "\n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} f(x) \\exp(-x^2)dx = \\sum_{i=1}^{n} f(x_i) + \\frac{n!\\sqrt{\\pi}}{2^n}\\frac{f^{(2n)}(\\xi)}{(2n)!}\n",
    "$$\n",
    "\n",
    "- Nodes and weights come from Hermite polynomials, values tabulated  \n",
    "- Good for computing expectation with Normal distribution \n",
    "$$\n",
    "E[f(y)]\n",
    "=(2\\pi\\sigma^2)^{-1/2}\\int_{-\\infty}^{\\infty} f(y)e^{-(y-\\mu)^2/(2\\sigma^2)}dy\n",
    "$$\n",
    "\n",
    "since normal density is proportional to $\\exp(-x^2)$ after  appropriate change of variable $x=(y-\\mu)/(\\sqrt{2}\\sigma)$ so that $y=\\sqrt{2}\\sigma x+ \\mu$ and $dy=\\sqrt{2}\\sigma dx$\n",
    "$$\n",
    "E[f(y)]\n",
    "=\\pi^{-1/2}\\int_{-\\infty}^{\\infty} f(\\sqrt{2}\\sigma x+ \\mu)e^{-x^2}dx\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approximation of joint distribution of $y_{i}|x_{i}$ using Gauss-Hermite\n",
    "We have an integral on this form\n",
    "\\begin{eqnarray*}\n",
    "&&\\int_{-.\\infty }^{\\infty }\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},c,\\beta\n",
    "\\right) \\frac{1}{\\sigma _{c}}\\phi \\left( c/\\sigma _{c}\\right) dc \\\\\n",
    "&=&\\pi^{-1/2}\\int_{-.\\infty }^{\\infty }\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},z\\sqrt{2\\sigma _{c}^{2}},\\beta \\right) \\exp \\left(-z^{2}\\right)dz\\\\\n",
    "&=&\\int_{-.\\infty }^{\\infty }h\\left( z\\right) \\exp \\left( -z^{2}\\right) dz \\cong \\sum_{j}w_{j}h\\left( z_{j}\\right)\\\\\n",
    "&=&\\pi^{-1/2}\\sum_{j=1}^{m}w_j\\prod_{t=1}^{T}f\\left( y_{t}|x_{it},z_j\\sqrt{2\\sigma _{c}^{2}},\\beta \\right)\\\\\n",
    "\\end{eqnarray*}\n",
    "where \n",
    "- $w_{j}$ are Hermite quadrature weights\n",
    "- $z_{j}$ are Hermite quadrature nodes\n",
    "- The more nodes - The higher the precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Effects: Maximum Simulated Likelihood Estimation\n",
    "\n",
    "Simulation Likelihood contribution individual $i$\n",
    "1. Take $R$ independent draws from the standard normal label them $\\eta^{r},$ $r=1,..,R$\n",
    "2. Compute $c_{i}^{r}=\\sigma _{c}\\eta ^{r}$\n",
    "3. Compute $\\prod_{t=1}^{T}f\\left( y_{it}|x_{it},c^{r},\\beta \\right) $ for each $r$\n",
    "3. Average the results and take logs \n",
    "$$\n",
    "\\hat{\\ell}_{i}\\left( \\theta \\right)=\\ln \\frac{1}{R}\\sum_{i=1}^{R}\\prod_{t=1}^{T}f\\left(\n",
    "y_{it}|x_{it},c^{r},\\beta \\right) \n",
    "$$\n",
    "\n",
    "**Estimation:**\n",
    "Maximize sample average of log of simulated likelihood w.r.t. $\\theta=\\left\\{ \\beta ,\\sigma _{c}^{2}\\right \\}$\n",
    "$$\n",
    "\\hat{\\theta}_{MSL}=\\arg \\max_{\\theta =\\left \\{ \\beta ,\\sigma _{c}^{2}\\right\\} }\\frac{1}{N}\\sum_{i=1}^{N}\\ln\\frac{1}{R}\\sum_{i=1}^{R}\\prod_{t=1}^{T}f\\left( y_{it}|x_{it},c^{r},\\beta \\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Remarks on Simulated Based Estimation\n",
    "\n",
    "Properties of MSL\n",
    "1. If R is fixed, MSL is inconsistent.\n",
    "2. If R rises slower than$\\sqrt{N}$, MSL is consistent but not asymptotically normal.\n",
    "3. If R rises faster than $\\sqrt{N}$, MSL is consistent, asymptotically normal and efficient, and equivalent to MLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to relax assumptions on unobserved effect within random effects framework?\n",
    "\n",
    "We can relax assumptions by re-specifying model\n",
    "- Serial correlation: Requires evaluation of $T$ dimensional integrals (use simulation methods)\n",
    "- Chamberlain approach: Specified correlation with $x_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fixed Effects Logit\n",
    "\n",
    "**The trick:**\n",
    "- Model the joint distribution of $y_{i}$ conditional on $x_{i}$, $c_{i}$ *and* $n_{i}=\\sum_{i}y_{it}$\n",
    "- In the logit model, it turns out that this does not depend on $c_{i}.$\n",
    "- For $T=2$ we have\n",
    "\\begin{eqnarray*}\n",
    "P\\left( y_{i2}=1|x_{i},c_{i},n_{i}=1\\right) &=&\\Lambda \\left( \\left(x_{i2}-x_{i1}\\right) \\beta \\right) \\\\\n",
    "P\\left( y_{i1}=1|x_{i},c_{i},n_{i}=1\\right) &=&1-\\Lambda \\left( \\left(\n",
    "x_{i2}-x_{i1}\\right) \\beta \\right) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "$$\n",
    "l_{i}\\left( \\beta \\right) =\\left(n_{i}=1\\right) \\left \\{ \n",
    "\\begin{array}{c} \n",
    "w_{i}\\Lambda \\left( \\left( x_{i2}-x_{i1}\\right) \\beta \\right) + \\\\ \n",
    "\\left( 1-w_{i}\\right) \\left( 1-\\Lambda \\left( \\left( x_{i2}-x_{i1}\\right) \\beta \\right) \\right)\n",
    "\\end{array}\n",
    "\\right \\} \n",
    "$$\n",
    "- NOTE: We cannot use this trick eliminate $c_{i}$ in the probit model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fixed Effects Logit: Identification\n",
    "Identification:\n",
    "- Conditional distribution of $y_{it}$ is not informative about $\\beta $, when $n_{i}=0$ or $n_{i}=T$ \n",
    "(since $n_{i}=0$ and $n_{i}=2$ perfectly predict $y_{it}$)\n",
    "- We therefore need time-series variation in $y_{it}$ to identify $\\beta $\n",
    "\n",
    "**Identified objects**\n",
    "- We can identify $\\beta$ (up to scale) and obtain the effect on the log-odd ratio:\n",
    "$$\n",
    "\\ln \\left[ \\frac{\\left( \\Lambda \\left( x_{t}^{\\prime }\\beta \\right) \\right) \n",
    "}{\\left( 1-\\Lambda \\left( x_{t}^{\\prime }\\beta \\right) \\right) }\\right] = x_{t}^{\\prime }\\beta +c%\n",
    "$$\n",
    "\n",
    "**Unidentified objects**\n",
    "- Partial effects cannot be estimated unless we assume *value* of $c$\n",
    "- $APE$ can't be estimated - since we do not assume *distribution* of $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simulation exercise\n",
    "Model \n",
    "\\begin{eqnarray*}\n",
    "y_{it}&=&1(z_{it} \\delta + \\rho y_{it-1} + c_i +e_{it}>0)\\\\\n",
    "c_i   &=& \\phi_0 + \\phi_{y0} y_{i0} + a_i\\\\\n",
    "a_i &\\sim&  iidN(0, \\sigma_a^2)\\\\\n",
    "e_{it} &\\sim& iidN(0, 1)\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       group  period    y         z   y0  const  l1.y\n",
      "1        0.0     1.0  0.0 -0.462061  1.0    1.0   1.0\n",
      "2        0.0     2.0  1.0  0.317448  1.0    1.0   0.0\n",
      "3        0.0     3.0  0.0 -0.283605  1.0    1.0   1.0\n",
      "4        0.0     4.0  0.0 -0.761805  1.0    1.0   0.0\n",
      "5        0.0     5.0  1.0  0.382990  1.0    1.0   0.0\n",
      "...      ...     ...  ...       ...  ...    ...   ...\n",
      "10995  999.0     6.0  1.0  1.637028  0.0    1.0   0.0\n",
      "10996  999.0     7.0  1.0  1.272161  0.0    1.0   1.0\n",
      "10997  999.0     8.0  1.0  1.865374  0.0    1.0   1.0\n",
      "10998  999.0     9.0  0.0 -0.459113  0.0    1.0   1.0\n",
      "10999  999.0    10.0  0.0 -0.916302  0.0    1.0   0.0\n",
      "\n",
      "[10000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from indexmodels import *\n",
    "df_sim=simulate(n=1000, nT=10, model='probit', rho=1, delta=1, phi_0=0, phi_y0=0, sigma_a=1)\n",
    "print(df_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Experiments - static models\n",
    "1. No heterogeneity \n",
    "    - does LPM give a good approximation of APE\n",
    "    - does pooled probit estimate true parameters\n",
    "    \n",
    "1. Neglect heterogeneity - Pooled probit or LPM\n",
    "   - does pooled probit estimate true parameters?\n",
    "   - does pooled OLS and probit still estimate APE\n",
    "\n",
    "1. Can RE-Probit estimate account for heterogeneity and uncover true parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Specification: Pooled OLS Panel Regression\n",
      "Dep. var. : y \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "z               0.1594      0.0052     30.6276\n",
      "const           0.4983      0.0114     43.7609\n",
      "# of groups:       1000\n",
      "# of observations: 10000 \n",
      "\n",
      "\n",
      "Specification: Linear Fixed Effects Regression\n",
      "Dep. var. : y \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "z               0.1599      0.0045     35.1982\n",
      "# of groups:       1000\n",
      "# of observations: 10000 \n",
      "\n",
      "Pooled probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               0.43447     0.01684    25.80177     0.00000     0.15896\n",
      "const          -0.00487     0.03110    -0.15652    -0.00005    -0.00178\n",
      "\n",
      "# of groups:      : 1000\n",
      "# of observations : 10000\n",
      "# log-likelihood. : -6396.414325386091 \n",
      "\n",
      "Iteration info: 3 iterations, 4 evaluations of objective, and 4 evaluations of gradients\n",
      "Elapsed time: 0.1291 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta=1; sigma_a=2\n",
    "df_sim=simulate(n=1000, nT=10, model='probit', delta=delta, sigma_a=sigma_a, phi_y0=0)\n",
    "lpm_ols=lpd.estim(df_sim, 'y', xvar=['z', 'const'], groupvar='group', method='pols', cov_type='robust')\n",
    "lpm_fe=lpd.estim(df_sim, 'y',  xvar=['z'], groupvar='group', method='fe', cov_type='robust')\n",
    "res_pp=pooled(df_sim, 'y', xvar =['z', 'const'] , groupvar='group', model='probit', cov_type='sandwich')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neglegted heterogeneity in pooled probit\n",
    "- Recall that we only estimate parameters up to a scale, $\\beta/\\sigma$,  where $\\sigma^2$ is the variance on the error component in the latent variable formulation. \n",
    "- To obtain identification for probit we normalize $\\sigma^2$ to one\n",
    "- We have two errors $v_{it}=a_i + e_{it}$ whose variance is $1+\\sigma_a^2$\n",
    "- So what we have estimated is $\\beta/\\sigma=\\beta/\\sqrt{1+\\sigma_a^2}$\n",
    "- Pooled probit consistently estimates $P(y_{it}|x_{it})=\\Phi({x\\beta/\\sigma})$ and average partial effect $E_c(\\beta/\\sigma \\phi(x\\beta+c))=E(\\beta/\\sigma \\phi(x\\beta/\\sigma))$\n",
    "- Is neglected heterogeneity a problem in static models?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               0.42077     0.01682    25.00885    -0.00002     0.15490\n",
      "const          -0.00074     0.03109    -0.02375    -0.00002    -0.00027\n",
      "\n",
      "# of groups:      : 1000\n",
      "# of observations : 10000\n",
      "# log-likelihood. : -6436.0157345385915 \n",
      "\n",
      "Iteration info: 3 iterations, 4 evaluations of objective, and 4 evaluations of gradients\n",
      "Elapsed time: 0.1347 seconds\n",
      "\n",
      "true delta                     : 1\n",
      "delta_hat - pooled probit      : 0.42076541913631227\n",
      "delta/(np.sqrt(1+sigma_a**2))  : 0.4472135954999579\n"
     ]
    }
   ],
   "source": [
    "df_sim=simulate(n=1000, nT=10, model='probit', delta=1, sigma_a=2, phi_y0=0)\n",
    "res_pp=pooled(df_sim, 'y', xvar =['z', 'const'] , groupvar='group', model='probit', cov_type='sandwich')\n",
    "print('true delta                     :' , delta)\n",
    "print('delta_hat - pooled probit      :' , res_pp.theta_hat[0,0])\n",
    "print('delta/(np.sqrt(1+sigma_a**2))  :' , delta/np.sqrt(1+sigma_a**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Can RE-Probit estimate account for heterogeneity and uncover true parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               0.72240     0.01379    52.38475     0.00000     0.23344\n",
      "const           0.02049     0.00738     2.77662    -0.00000     0.00662\n",
      "\n",
      "# of groups:      : 1000\n",
      "# of observations : 10000\n",
      "# log-likelihood. : -5689.1346068971 \n",
      "\n",
      "Iteration info: 4 iterations, 5 evaluations of objective, and 5 evaluations of gradients\n",
      "Elapsed time: 0.1679 seconds\n",
      "\n",
      "Random effects probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               1.02584     0.02180    47.06554     0.00000     0.23547\n",
      "const           0.02701     0.03506     0.77034     0.00000     0.00620\n",
      "sigma_a         0.98183     0.03287    29.87283     0.00000     0.22537\n",
      "\n",
      "# of groups:      : 1000\n",
      "# of observations : 10000\n",
      "# log-likelihood. : -4892.543351461452 \n",
      "\n",
      "Iteration info: 6 iterations, 7 evaluations of objective, and 7 evaluations of gradients\n",
      "Elapsed time: 0.5593 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sim=simulate(n=1000, nT=10, model='probit', delta=1, sigma_a=1, phi_y0=0)\n",
    "res_rep=pooled(df_sim, 'y', xvar =['z', 'const'] , groupvar='group', model='probit', cov_type='Binv')\n",
    "res_rep=rand_effect(df_sim, 'y', xvar =['z', 'const'] , groupvar='group', model='probit', cov_type='Binv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dynamic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dynamic Unobserved Effects Models\n",
    "\n",
    "**Dynamic model**\n",
    "\n",
    "$$\n",
    "P\\left( y_{it}=1|y_{it-1},y_{it-2},....,y_{i0},z_{i},c_{i}\\right) =G\\left(\n",
    "z_{it}\\delta +\\rho y_{it-1}+c_{i}\\right) \n",
    "$$\n",
    "\n",
    "\n",
    "- Interest is in coefficient on lagged dependent variable (state dependence)\n",
    "- $z_{it}$ is strictly exogenous\n",
    "\n",
    "**Important to appropriately control for $c_{i}$ and $y_{i0}$**\n",
    "- To avoid *spurious state dependence*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to deal with unobserved effect\n",
    "\n",
    "1. **Estimate $c_{i}$ ?**\n",
    "\t- **NO:** Incidental parameters problem is even more severe in dynamic models (Heckman 1981)\n",
    "    \n",
    "2. **Dynamic Random Effects Model**\n",
    "\t- Integrate out $c_{i}$\n",
    "\t- Initial condition problem: $c_{i}$ is likely to be correlated with initial conditions $y_{i0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to deal initial conditions problem\n",
    "**Several approaches**\n",
    "1. Treat $y_{i0}$ as non-random, i.e. assume independence between $y_{i0}$ and $c_{i}$ (*very* strong assumption)\n",
    "2. Chamberlain approach: \n",
    "\t- Assume distribution for $c|y_{0};z$ \n",
    "\t- Leading example: $N\\left( \\psi +\\xi _{0}y_{i0}+z_{i}\\xi ,\\sigma_{a}\\right) $\n",
    "\t- Approximation of distribution for $y_{i0}|z_{i},c_{i}$ (Heckman, 1981)\n",
    "3. Semiparametric approaches \n",
    "\t- in a model with fixed effects (Honoré and Kyriazidou, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A simple solution to initial conditions in the probit model\n",
    "**Chamberlain/Wooldridge approach:**\n",
    "\n",
    "Assume \n",
    "$$\n",
    "c|y_{0};z\\sim N\\left( \\psi +\\xi _{0}y_{i0}+z_{i}\\xi ,\\sigma _{a}\\right) \n",
    "$$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "c_{i} &=&\\psi +\\xi _{0}y_{i0}+z_{i}\\xi +a_{i} \\\\\n",
    "a_{i} &\\sim &N\\left( 0,\\sigma _{a}\\right) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "For the probit model, $G\\left( {}\\right) =\\Phi \\left( {}\\right) $ we have latent variable form\n",
    "\\begin{eqnarray*}\n",
    "y_{it} &=&1\\left[ z_{it}\\delta +\\rho y_{it-1}+c_{i}+e_{it}\\right] \\\\\n",
    "&=&1\\left[ z_{it}\\delta +\\rho y_{it-1}+\\psi +\\xi _{0}y_{i0}+z_{i}\\xi+a_{i}+e_{it}\\right] \n",
    "\\end{eqnarray*}\n",
    "where $e_{it}\\sim N\\left( 0,1\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A simple solution to initial conditions in the probit model\n",
    "\n",
    "**Chamberlain/Wooldridge approach:**\n",
    "\n",
    "Recall the estimating equation\n",
    "\n",
    "$$\n",
    "y_{it}=1\\left[ z_{it}\\delta +\\rho y_{it-1}+\\psi +\\xi _{0}y_{i0}+z_{i}\\xi+a_{i}+e_{it}\\right] \n",
    "$$\n",
    "\n",
    "- This equation can be estimated by a standard random effects probit\n",
    "- Simply add $y_{i0}$ and $z_{i}$ to the conditioning set to take account of\n",
    "\t1. initial conditions problem\n",
    "\t2. specified correlation between $c_{i}$ and $z_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simulation exercise\n",
    "Model \n",
    "\\begin{eqnarray*}\n",
    "y_{it}&=&1(z_{it} \\delta + \\rho y_{it-1} + c_i +e_{it}>0)\\\\\n",
    "c_i   &=& \\phi_0 + \\phi_{y0} y_{i0} + a_i\\\\\n",
    "a_i &\\sim&  iidN(0, \\sigma_a^2)\\\\\n",
    "e_{it} &\\sim& iidN(0, 1)\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Experiments - dynamic models models    \n",
    "1. Neglecting heterogeneity and initial conditions\n",
    "   - does pooled OLS and probit consistently estimate APE of lagged y (state dependence)?\n",
    "   - what about other parameters?\n",
    "1. Accounting for heterogeneity and initial conditions \n",
    "    - is LPM-FE valid for dynamic models?\n",
    "    - can RE probit estimate APE of lagged y (state dependence)?\n",
    "    - what if x is correlated with c_i?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexmodels import *\n",
    "xit=['z', 'l1.y']; xi=['const', 'y0']\n",
    "df_sim=simulate(n=2000, nT=10, model='probit', delta=1, sigma_a=3, phi_y0=0)\n",
    "lpm_ols=lpd.estim(df_sim, 'y', xvar=xit + xi, groupvar='group', method='pols', cov_type='robust')\n",
    "res_pp=pooled(df_sim, 'y', xvar =xit + xi, groupvar='group', model='probit')\n",
    "lpm_fe=lpd.estim(df_sim, 'y',  xvar=xit, groupvar='group', method='fe', cov_type='robust')\n",
    "res_rep=rand_effect(df_sim, 'y', xvar =xit + xi , groupvar='group',model='probit', cov_type='sandwich', deriv=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Essential to account for initial conditions and unobserved effects in dynamic models\n",
    "- Is persitence in y due to initial conditions, unobserved effects or true state dependence\n",
    "- Policy implications are very different\n",
    "- Example: Smoking/Drugs. Makes a big difference for policy intervention if persistence is driven by previous smoking or individual taste differences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Panel data: Married women's labor force participation \n",
    "Let's first create some variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "xbar_i=x_it.copy()\n",
    "i=0\n",
    "for j in x_it:\n",
    "    xbar_i[i]=j + '_bar'\n",
    "    df[j + '_bar']= df[j].groupby(df[groupvar]).transform('mean')\n",
    "    i+=1\n",
    "df\n",
    "df[['id', 'period'] +  y_it + x_it + xbar_i + x_i][50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from indexmodels import *\n",
    "res_pp=pooled(df, y_it, xvar=x_it + xbar_i + x_i + x_t + ['const'] , groupvar='id', model='probit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_a0=1\n",
    "theta0=res_pp.theta_hat*np.sqrt(1+sigma_a0**2)\n",
    "theta0=np.append(theta0,sigma_a0).reshape(-1,1)\n",
    "xvar=x_it + xbar_i + x_i + x_t + ['const']\n",
    "from indexmodels import *\n",
    "res_rep=rand_effect(df, y_it,xvar, groupvar='id', theta0=theta0)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "date": 1602643870.398518,
  "filename": "38_optimization.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "title": "Foundations of Computational Economics #38"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
